{
  "hash": "7ea7a23a8b909d4616d9493af342d3c7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Checking assumptions\"\noutput: html_document\nlightbox: true\n---\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n::: callout-tip\n## Learning outcomes\n\n-   Know what statistical assumptions apply to logistic regression (and GLMs)\n-   Be able to evaluate whether a logistic regression meets the assumptions\n:::\n\n## Context\nWe can now assess the quality of a generalised linear model. Although we can relax certain assumptions compared to standard linear models (linearity, equality of variance of residuals, and normality of residuals), we cannot relax all of them - some key assumptions still exist. We discuss these below.\n\n## Libraries and functions\n\n:::: {.callout-note collapse=\"true\"}\n## Click to expand\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggResidpanel)\nlibrary(performance)\n```\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nfrom plotnine import *\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.stats import *\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom patsy import dmatrix\n```\n:::\n\n:::\n:::\n\n### Assumption 1: Distribution of response variable\n\nAlthough we don't expect our response variable $y$ to be continuous and normally distributed (as we did in linear modelling), we do still expect its distribution to come from the \"exponential family\" of distributions.\n\n::: callout.tip\n#### The exponential family\n\nThe exponential family contains the following distributions, among others:\n\n-   normal\n-   exponential\n-   Poisson\n-   Bernoulli\n-   binomial (for fixed number of trials)\n-   chi-squared\n:::\n\nYou can use a histogram to visualise the distribution of your response variable, but it is typically most useful just to think about the nature of your response variable. For instance, binary variables will follow a Bernoulli distribution, proportional variables follow a binomial distribution, and most count variables will follow a Poisson distribution.\n\nIf you have a very unusual variable that doesn't follow one of these exponential family distributions, however, then a GLM will not be an appropriate choice. In other words, a GLM is not necessarily a magic fix!\n\n### Assumption 2: Correct link function\n\nA closely-related assumption to assumption 1 above, is that we have chosen the correct link function for our model.\n\nIf we have done so, then there should be a linear relationship between our *transformed* model and our response variable; in other words, if we have chosen the right link function, then we have correctly \"linearised\" our model.\n\n### Assumption 3: Independence\n\nWe expect that the each observation or data point in our sample is independent of all the others. Specifically, we expect that our set of $y$ response variables are independent of one another.\n\nFor this to be true, we have to make sure:\n\n-   that we aren't treating technical replicates as true/biological replicates;\n-   that we don't have observations/data points in our sample that are artificially similar to each other (compared to other data points);\n-   that we don't have any nuisance/confounding variables that create \"clusters\" or hierarchy in our dataset;\n-   that we haven't got repeated measures, i.e., multiple measurements/rows per individual in our sample\n\nThere is no diagnostic plot for assessing this assumption. To determine whether your data are independent, you need to understand your experimental design.\n\nYou might find [this page](https://cambiotraining.github.io/experimental-design/materials/04-replication.html#criteria-for-true-independent-replication) useful if you're looking for more information on what counts as truly independent data.\n\n## Other features to check\n\nThere are a handful of other features or qualities that can affect the quality of model fit, and therefore the quality of the inferences we draw from it.\n\nThese are not necessarily \"formal\" assumptions, but it's good practice to check for them.\n\n#### Lack of influential observations\n\nA data point is overly influential, i.e., has high leverage, if removing that point from the dataset would cause large changes in the model coefficients. Data points with high leverage are typically those that don't follow the same general \"trend\" as the rest of the data.\n\n#### Lack of collinearity\n\nCollinearity is when predictor variables are overly/strongly correlated with each other. This can make it very difficult to estimate the right beta coefficients and individual p-values for those predictors.\n\n#### Dispersion\n\nThis is mentioned here for completeness, and as a bit of sizzle for next chapter when we talk about Poisson regression.\n\nWe won't be worrying about dispersion in logistic regression specifically.\n\nIf you want more detail, you can skip ahead now to [Section @sec-mat_dispersion].\n\n## Assessing assumptions & quality\n\nIn linear modelling, we rely heavily on visuals to determine whether various assumptions were met.\n\nWhen checking assumptions and assessing quality of fit for GLMs, we don't use the panel of diagnostic plots that we used for linear models any more. However, there are some visualisations that can help us, plus several metrics we can calculate from our data or model.\n\n+-----------------------------------------------------------------------+----------------------------+----------------------------------------------------------------------------+\n|                                                                       | Is it a formal assumption? | How can I assess it?                                                       |\n+=======================================================================+============================+============================================================================+\n| Response variable comes from a distribution in the exponential family | Yes                        | Knowledge of the experimental design                                       |\n|                                                                       |                            |                                                                            |\n| &                                                                     |                            | *Some plots, e.g., posterior predictive check/uniform Q-Q, may help*       |\n|                                                                       |                            |                                                                            |\n| The model uses the right link function                                |                            |                                                                            |\n+-----------------------------------------------------------------------+----------------------------+----------------------------------------------------------------------------+\n| Independent observations                                              | Yes                        | Knowledge of experimental design                                           |\n|                                                                       |                            |                                                                            |\n|                                                                       |                            | *There are **no** formal tests or plots that assess independence reliably* |\n+-----------------------------------------------------------------------+----------------------------+----------------------------------------------------------------------------+\n| Influential observations                                              | No                         | Cook's distance/leverage plot                                              |\n+-----------------------------------------------------------------------+----------------------------+----------------------------------------------------------------------------+\n| Lack of collinearity                                                  | No                         | Variance inflation factor                                                  |\n+-----------------------------------------------------------------------+----------------------------+----------------------------------------------------------------------------+\n| Dispersion                                                            | Sort of                    | Calculating the dispersion parameter                                       |\n|                                                                       |                            |                                                                            |\n|                                                                       |                            | Can also be visualised                                                     |\n+-----------------------------------------------------------------------+----------------------------+----------------------------------------------------------------------------+\n\nLet's fit some useful diagnostic plots, using the `diabetes` and `aphids` example datasets.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes <- read_csv(\"data/diabetes.csv\")\n\nglm_dia <- glm(test_result ~ glucose * diastolic,\n                  family = \"binomial\",\n                  data = diabetes)\n```\n:::\n\n\nWe're going to rely heavily on the `performance` package in R for assessing the assumptions and fit of our model.\n\nThe `check_model` function will be our primary workhorse. This function automatically detects the type of model you give it, and produces the appropriate panel of plots all by itself. (So, so cool. And yes, it works for linear models too!)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(glm_dia)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-11-checking-assumptions_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndiabetes_py = pd.read_csv(\"data/diabetes.csv\")\n\nmodel = smf.glm(formula = \"test_result ~ glucose * diastolic\",\n                family = sm.families.Binomial(),\n                data = diabetes_py)\n\nglm_dia_py = model.fit()\n```\n:::\n\n:::\n\n### Influential observations\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe can check for outliers via a leverage plot (in `performance`), which you may remember from linear modelling.\n\nIdeally, data points would fall inside the green contour lines. Data points that don't will be highlighted in red.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(glm_dia, check = 'outliers')\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-11-checking-assumptions_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nAlternatively, we can use the `check_outliers` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_outliers(glm_dia, threshold = list('cook' = 0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.5).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n## Python\n\nWe can use the `get_influence` function to extract information like leverage, Cook's distance etc. about all of our data points:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# extract the Cook's distances\nglm_dia_py_resid = pd.DataFrame(glm_dia_py.\n                                get_influence().\n                                summary_frame()[\"cooks_d\"])\n\n# add row index \nglm_dia_py_resid['obs'] = glm_dia_py_resid.reset_index().index\n```\n:::\n\n\n\nWe now have two columns:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nglm_dia_py_resid.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    cooks_d  obs\n0  0.000709    0\n1  0.000069    1\n2  0.000641    2\n3  0.000080    3\n4  0.009373    4\n```\n\n\n:::\n:::\n\n\nWe can use these to create the plot:\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(glm_dia_py_resid,\n         aes(x = \"obs\",\n             y = \"cooks_d\")) +\n     geom_segment(aes(x = \"obs\", y = \"cooks_d\", xend = \"obs\", yend = 0)) +\n     geom_point())\n\np.show()\n```\n\n::: {.cell-output-display}\n![](glm-11-checking-assumptions_files/figure-html/unnamed-chunk-12-1.png){width=614}\n:::\n:::\n\n\n::: {.callout-tip collapse=true}\n## Alternative method using `matplotlib`\n\n\n::: {.cell}\n\n```{.python .cell-code}\ninfluence = glm_dia_py.get_influence()\n```\n:::\n\n\nThen, we can visualise and interrogate that information.\n\nWe can produce a Cook's distance plot (this uses `matplotlib`):\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncooks = influence.cooks_distance[0]\n\nplt.stem(np.arange(len(cooks)), cooks, markerfmt=\",\")\nplt.axhline(0.5, color='red', linestyle='--', label='Threshold')\nplt.xlabel('Observation')\nplt.ylabel(\"Cook's Distance\")\nplt.title(\"Cook's Distance Plot\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](glm-11-checking-assumptions_files/figure-html/unnamed-chunk-14-3.png){width=672}\n:::\n:::\n\n\nand/or we can extract a list of data points with a Cook's distance greater than some specified threshold:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ninfluential_points = np.where(cooks > 0.5)[0] # Set appropriate threshold here\n\nprint(\"Influential points:\", influential_points)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluential points: []\n```\n\n\n:::\n:::\n\n\nThe list is empty, indicating no high leverage points that we need to worry about.\n:::\n\nWe can check which points may be influential, for example by setting a threshold of > 0.5:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ninfluential_points = glm_dia_py_resid[glm_dia_py_resid[\"cooks_d\"] > 0.5]\n\nprint(\"Influential points:\", influential_points)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluential points: Empty DataFrame\nColumns: [cooks_d, obs]\nIndex: []\n```\n\n\n:::\n:::\n\n\nThe DataFrame is empty, indicating no high leverage points that we need to worry about.\n\n:::\n\n::: callout-warning\n#### Dealing with \"outliers\"\n\nRemember:\n\n-   Outliers and influential points aren't necessarily the same thing; all outliers need to be followed up, to check *if* they are influential in a problematic way\n-   You **can't just drop** data points because they are inconvenient! This is cherry-picking, and it can impact the quality and generalisability of your conclusions\n:::\n\n### Lack of collinearity\n\nThe best way to assess whether we have collinearity is to look at something called the variance inflation factor (VIF).\n\nWhen calculating VIF for a model, a separate VIF value will be generated for each predictor. VIF \\>5 is worth an eyebrow raise; VIF \\>10 definitely needs some follow-up; and VIF \\>20 suggests a really strong correlation that is definitely problematic.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_collinearity(glm_dia)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nModel has interaction terms. VIFs might be inflated.\n  Try to center the variables used for the interaction, or check\n  multicollinearity among predictors of a model without interaction terms.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Check for Multicollinearity\n\nHigh Correlation\n\n              Term   VIF     VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n           glucose 37.99 [32.97, 43.80]     6.16      0.03     [0.02, 0.03]\n         diastolic 24.24 [21.06, 27.92]     4.92      0.04     [0.04, 0.05]\n glucose:diastolic 69.45 [60.21, 80.14]     8.33      0.01     [0.01, 0.02]\n```\n\n\n:::\n:::\n\n\nWe can also visualise the VIFs, if we prefer, with the VIF plot in `check_model`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(glm_dia, check = \"vif\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-11-checking-assumptions_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n## Python\n\nThe `statsmodels` package contains a function for calculating VIF.\n\nIt uses the original dataset, rather than the model, to do this. This means you have to manually exclude the response variable, and then use the `dmatrix` function from `patsy` to .\n\nTo make sure all that\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom patsy import dmatrix\n\n# Drop the response variable\nX = diabetes_py.drop(columns='test_result')\n\n# Create design matrix based on model formula\nX = dmatrix(\"glucose * diastolic\", data=diabetes_py, return_type='dataframe')\n\n# Calculate VIF for each feature\nvif_data = pd.DataFrame()\nvif_data['feature'] = X.columns\nvif_data['VIF'] = [variance_inflation_factor(X.values, i)\n                   for i in range(X.shape[1])]\n\nprint(vif_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             feature         VIF\n0          Intercept  600.539179\n1            glucose   36.879125\n2          diastolic   17.407953\n3  glucose:diastolic   63.987700\n```\n\n\n:::\n:::\n\n:::\n\nThere is definitely some collinearity going on in our model - these VIF values are way over 10.\n\nThe most likely culprit for this is the interaction term - let's see if we can improve things by dropping it:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_dia_add <- glm(test_result ~ glucose + diastolic,\n                  family = \"binomial\",\n                  data = diabetes)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_collinearity(glm_dia_add)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Check for Multicollinearity\n\nLow Correlation\n\n      Term  VIF   VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n   glucose 1.02 [1.00, 1.78]     1.01      0.98     [0.56, 1.00]\n diastolic 1.02 [1.00, 1.78]     1.01      0.98     [0.56, 1.00]\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_model(glm_dia_add, check = \"vif\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-11-checking-assumptions_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## Python\n\nWe will try again, this time without manually adding the interaction:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# 1. Drop the response variable\nX = diabetes_py.drop(columns='test_result')\n\n# 2. Add constant column for intercept\nX = sm.add_constant(X)\n\n# Calculate VIF for each feature\nvif_data = pd.DataFrame()\nvif_data['feature'] = X.columns\nvif_data['VIF'] = [variance_inflation_factor(X.values, i)\n                   for i in range(X.shape[1])]\n\nprint(vif_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     feature        VIF\n0      const  42.747425\n1    glucose   1.052426\n2  diastolic   1.052426\n```\n\n\n:::\n:::\n\n:::\n\nMuch better!\n\n## Exercises\n\n### Revisiting rats and levers (again) {#sec-exr_levers-again-again}\n\n::: {.callout-exercise}\n####Revisiting rats and levers (again)\n\n{{< level 2 >}}\n\nIn [Exercise @sec-exr_levers] and [Exercise @sec-exr_levers-again], you worked through the `levers` dataset, fitting an appropriate model and then assessing its significance.\n\nNow, using what you've learned in this chapter, assess whether this logistic regression is appropriate:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevers <- read_csv(\"data/levers.csv\")\n\nlevers <- levers |> \n  mutate(incorrect_presses = trials - correct_presses)\n\nglm_lev <- glm(cbind(correct_presses, incorrect_presses) ~ stress_type * sex + rat_age,\n               family = binomial,\n               data = levers)\n```\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlevers = pd.read_csv(\"data/levers.csv\")\n\nlevers['incorrect_presses'] = levers['trials'] - levers['correct_presses']\n\nmodel = smf.glm(formula = \"correct_presses + incorrect_presses ~ stress_type * sex + rat_age\",\n                family = sm.families.Binomial(),\n                data = levers)\n\nglm_lev = model.fit()\n```\n:::\n\n:::\n\n::: {.callout-answer collapse=\"true\"}\n#### Consider the response variable\n\nIs a logistic regression, with a logit link function, appropriate?\n\nFor the answer to be \"yes\", then our response variable needs to be either a binary or a proportional variable (binomially distributed). We're looking for those success/fail trials.\n\nSometimes, it can help to visualise the design:\n  \n  ![Experimental design for rat lever experiment](images/rats-levers-design.png){width=70%}\n\nWe can see that for each rat, the proportion score is made up of a series of trials, each of which can either be correct (+) or incorrect (-). \n\n#### Consider independence\n\nAgain, we need to think about the design.\n\nIt might initially seem as if we have multiple observations per animal - since each rat pressed a whole bunch of levers - but actually if we look at each row of our dataset:\n  \n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(levers)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 8\n  rat_id stress_type sex    rat_age trials correct_presses prop_correct\n   <dbl> <chr>       <chr>    <dbl>  <dbl>           <dbl>        <dbl>\n1      1 control     female      13     20               7         0.35\n2      2 control     female      15     20              11         0.55\n3      3 control     female      11     20               5         0.25\n4      4 control     female      15     20               5         0.25\n5      5 stressed    female      13     20               8         0.4 \n6      6 stressed    male        14     20               8         0.4 \n# ℹ 1 more variable: incorrect_presses <dbl>\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlevers.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   rat_id stress_type     sex  ...  correct_presses  prop_correct  incorrect_presses\n0       1     control  female  ...                7          0.35                 13\n1       2     control  female  ...               11          0.55                  9\n2       3     control  female  ...                5          0.25                 15\n3       4     control  female  ...                5          0.25                 15\n4       5    stressed  female  ...                8          0.40                 12\n\n[5 rows x 8 columns]\n```\n\n\n:::\n:::\n\n:::\n  \n  it becomes clear that each row of the dataset represents a rat, rather than each row representing a separate trial/button press.\n\nIn other words: by collecting the proportion of correct trials, we have averaged across the rat, and so it only appears once in our dataset.\n\nThis means that each of the rows of the dataset truly are independent.\n\nNow, this does make some assumptions about the nature of the rats' relationships to each other. Some non-independence could be introduced if:\n\n-   Some of the rats are genetically more similar to each other, e.g., if multiple rats from the same litter were included\n-   Rats were trained together before testing\n-   Rats were exposed to stress in one big batch (i.e., putting them all in one cage with the smell of a predator) rather than individually\n\n#### Influential observations\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(glm_lev, check = 'outliers')\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-11-checking-assumptions_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncheck_outliers(glm_lev)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.5).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ninfluence = glm_lev.get_influence()\n\ncooks = influence.cooks_distance[0]\n\nplt.stem(np.arange(len(cooks)), cooks, markerfmt=\",\")\nplt.axhline(0.5, color='red', linestyle='--', label='Threshold')\nplt.xlabel('Observation')\nplt.ylabel(\"Cook's Distance\")\nplt.title(\"Cook's Distance Plot\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](glm-11-checking-assumptions_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ninfluential_points = np.where(cooks > 0.5)[0] # Set appropriate threshold here\n\nprint(\"Influential points:\", influential_points)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluential points: []\n```\n\n\n:::\n:::\n\n:::\n\nLooks good!\n\n#### Collinearity\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_collinearity(glm_lev)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Check for Multicollinearity\n\nLow Correlation\n\n            Term  VIF     VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n     stress_type 1.81 [1.40,   2.64]     1.34      0.55     [0.38, 0.72]\n             sex 2.23 [1.66,   3.28]     1.49      0.45     [0.30, 0.60]\n         rat_age 1.02 [1.00, 287.92]     1.01      0.98     [0.00, 1.00]\n stress_type:sex 2.70 [1.97,   4.01]     1.64      0.37     [0.25, 0.51]\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_model(glm_lev, check = \"vif\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-11-checking-assumptions_files/figure-html/unnamed-chunk-30-3.png){width=672}\n:::\n:::\n\n\n## Python\n\nRemember to drop the response variables (and also rat ID in this case).\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Drop the response variable\nX = levers.drop(columns=['rat_id','correct_presses','prop_correct','incorrect_presses'])\n\n# Create design matrix\nX = dmatrix(\"stress_type * sex + rat_age\", data=levers, return_type='dataframe')\n\n# Calculate VIF for each feature\nvif_data = pd.DataFrame()\nvif_data['feature'] = X.columns\nvif_data['VIF'] = [variance_inflation_factor(X.values, i)\n                   for i in range(X.shape[1])]\n\nprint(vif_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                               feature        VIF\n0                            Intercept  48.157694\n1              stress_type[T.stressed]   1.768004\n2                          sex[T.male]   2.190167\n3  stress_type[T.stressed]:sex[T.male]   2.799690\n4                              rat_age   1.016442\n```\n\n\n:::\n:::\n\n:::\n\nAgain, all good - none of our predictors have a concerning VIF.\n\nCollectively, it would seem that our model does indeed meet the assumptions, and there are no glaring obstacles to us proceeding with a significance test and an interpretation.\n:::\n:::\n\n### Seed germination {#sec-exr_seed-germination}\n\n::: {.callout-exercise #ex-seed_germination}\n#### Seed germination\n\n{{< level 3 >}}\n\nThis exercise uses a new dataset, `seeds`, which is all about a seed germination experiment.\n\nEach row of the dataset represents a seed tray, in which 25 seeds were planted. The trays were treated with one of two light conditions (`sun`, `shade`) and one of three watering frequencies (`low`, `medium`, `high`).\n\nThe researchers want to know whether either or both of these predictors have an affect on the proportion of seeds that successfully germinate.\n\nIn this exercise, you should:\n\n1.  Visualise the data\n2.  Fit a suitable model\n3.  Test the assumptions and quality of model fit\n4.  Decide whether to draw a biological conclusion from the data\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseeds <- read_csv(\"data/seeds.csv\")\n```\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nseeds = pd.read_csv(\"data/seeds.csv\")\n```\n:::\n\n:::\n\nThere is no formal worked answer provided. However, all of the code you will need can be adapted from the `diabetes` and `aphids` examples worked through in the chapter.\n\nYou are also strongly encouraged to work with, or share your answer with, a neighbour.\n\n:::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n-   Consider a possible interaction effect\n-   Look closely at the dataset itself, and all its columns\n-   You should find at least two issues and/or failures of assumptions!\n\nIt may help to visualise the experimental design (the number of trays has been simplified so that the figure fits on the page):\n\n![Seed germination experiment](images/seeds-design.png){width=70%}\n:::\n\n:::\n\n## Summary\n\nWhile generalised linear models make fewer assumptions than standard linear models, we do still expect certain things to be true about the model and our variables for GLMs to be valid.\n\n::: {.callout-tip}\n#### Key points\n\n-   For a generalised linear model, we assume that we have chosen the correct link function, that our response variable follows a distribution from the exponential family, and that our data are independent\n-   We also want to check that there are no overly influential points, no collinearity, and that the dispersion parameter is close to 1\n-   To assess some of these assumptions/qualities, we have to rely on our understanding of our dataset\n-   For others, we can calculate metrics like Cook's distance and variance inflation factor, or produce diagnostic plots\n:::\n",
    "supporting": [
      "glm-11-checking-assumptions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}