{
  "hash": "a129df49c41f597ba422a8e5ca08ccb7",
  "result": {
    "markdown": "---\ntitle: \"Binary response\"\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n::: {.callout-tip}\n## Learning outcomes\n\n**Questions**\n\n-   How do we analyse data with a binary outcome?\n-   Can we test if our model is any good?\n-   Be able to perform a logistic regression with a binary outcome\n-   Predict outcomes of new data, based on a defined model\n\n**Objectives**\n\n- Be able to analyse binary outcome data\n- Understand different methods of testing model fit\n- Be able to make model predictions\n:::\n\n## Libraries and functions\n\n::: {.callout-note collapse=\"true\"}\n## Click to expand\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n### Libraries\n### Functions\n\n## Python\n\n### Libraries\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# A Python data analysis and manipulation tool\nimport pandas as pd\n\n# Python equivalent of `ggplot2`\nfrom plotnine import *\n\n# Statistical models, conducting tests and statistical data exploration\nimport statsmodels.api as sm\n\n# Convenience interface for specifying models using formula strings and DataFrames\nimport statsmodels.formula.api as smf\n```\n:::\n\n\n### Functions\n:::\n:::\n\nThe example in this section uses the following data set:\n\n`data/diabetes.csv`\n\nThis is a data set comprising 768 observations of three variables (one dependent and two predictor variables). This records the results of a diabetes test result as a binary variable (1 is a positive result, 0 is a negative result), along with the result of a glucose test and the diastolic blood pressure for each of 767 women. The variables are called `test_result`, `glucose` and `diastolic`.\n\n## Load and visualise the data\n\nFirst we load the data, then we visualise it.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes <- read_csv(\"data/diabetes.csv\")\n```\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndiabetes_py = pd.read_csv(\"data/diabetes.csv\")\n```\n:::\n\n\n:::\n\nLooking at the data, we can see that the `test_result` column contains zeros and ones. These are yes/no test result outcomes and not actually numeric representations.\n\nWe'll have to deal with this soon. For now, we can plot the data, by outcome:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes %>% \n  ggplot(aes(x = factor(test_result),\n             y = glucose)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](glm-practical-logistic-binary_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n## Python\n\nWe could just give Python the `test_result` data directly, but then it would view the values as numeric. Which doesn't really work, because we have two groups as such: those with a negative diabetes test result, and those with a positive one.\n\nWe can force Python to temporarily covert the data to a factor, by making the `test_result` column an `object` type. We can do this directly inside the `ggplot()` function.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(ggplot(diabetes_py,\n         aes(x = diabetes_py.test_result.astype(object),\n             y = \"glucose\")) +\n     geom_boxplot())\n```\n\n::: {.cell-output-display}\n![](glm-practical-logistic-binary_files/figure-html/unnamed-chunk-7-1.png){width=614}\n:::\n:::\n\n:::\n\nIt looks as though the patients with a positive diabetes test have slightly higher glucose levels than those with a negative diabetes test.\n\nWe can visualise that differently by plotting all the data points as a classic binary response plot:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes %>% \n  ggplot(aes(x = glucose, y = test_result)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](glm-practical-logistic-binary_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(ggplot(diabetes_py,\n         aes(x = \"glucose\",\n             y = \"test_result\")) +\n     geom_point())\n```\n\n::: {.cell-output-display}\n![](glm-practical-logistic-binary_files/figure-html/unnamed-chunk-9-1.png){width=614}\n:::\n:::\n\n\n:::\n\nThis presents us with a bit of an issue. We could fit a linear regression model to these data, although we already know that this is a bad idea...\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes %>% \n  ggplot(aes(x = glucose, y = test_result)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](glm-practical-logistic-binary_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(ggplot(diabetes_py,\n         aes(x = \"glucose\",\n             y = \"test_result\")) +\n     geom_point() +\n     geom_smooth(method = \"lm\",\n                 colour = \"blue\"))\n```\n\n::: {.cell-output-display}\n![](glm-practical-logistic-binary_files/figure-html/unnamed-chunk-11-1.png){width=614}\n:::\n:::\n\n\n:::\n\nOf course this is rubbish - we can't have test results outside the range of \\[0, 1\\].\n\nBut for the sake of exploration, let's look at the assumptions:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_dia <- lm(test_result ~ glucose,\n             data = diabetes)\n\nlm_dia %>% \n  resid_panel(plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula 'y ~ x'\n`geom_smooth()` using formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](glm-practical-logistic-binary_files/figure-html/unnamed-chunk-12-3.png){width=672}\n:::\n:::\n\n\n## Python\n\nFirst, we create a linear model:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# create a linear model\nmodel = smf.ols(formula= \"test_result ~ glucose\",\n                data = diabetes_py)\n# and get the fitted parameters of the model\nlm_dia_py = model.fit()\n```\n:::\n\n\nNext, we can create the diagnostic plots:\n\n::: {.cell}\n\n```{.python .cell-code}\ndgplots(lm_dia_py)\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/dgplots/2023_02_06-11:08:41_am_dgplots.png){width=794}\n:::\n:::\n\n\n:::\n\nThey're ~~pretty~~ extremely bad.\n\n-   The response is not linear (Residual Plot, binary response plot, common sense).\n-   The residuals are not distributed normally (Q-Q Plot)\n-   The variance is not homogeneous across the predicted values (Location-Scale Plot)\n-   But - there is always a silver lining - we don't have influential data points.\n\n::: {.callout-note}\n## Viewing residuals\n\nAnother way of viewing the residuals (apart from the Q-Q plot) is as a dot-plot. In R, the `ggdist` and `distributional` packages are extremely useful for this kind of stuff.\n\nWhat I'm doing here is:\n\n-   define the model\n-   create a normal distribution with $\\mu = 0$ and $\\sigma = 0.415$ (I've extracted the $\\sigma$ value from the residuals with `rstatix::get_summary_stats()`)\n-   plot the residuals\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes %>% \n  lm(test_result ~ glucose, data = .) %>%\n  resid() %>%\n  as_tibble() %>%\n  # rstatix::get_summary_stats()\n  ggplot(aes(x = value)) +\n  stat_dist_halfeye(aes(dist = dist_normal(0, 0.415)),\n                    orientation = \"horizontal\") +\n  stat_dotsinterval(aes(x = value),\n                    orientation = \"horizontal\",\n                    fill = \"firebrick\", scale = 1) +\n  labs(title = \"Linear model (diabetes)\", y = \"probability\", x = NULL)\n```\n\n::: {.cell-output-display}\n![](glm-practical-logistic-binary_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nThis again shows us that the residuals are really not normally distributed. If they were, then they would overlap much more closely with the distribution (in grey).\n:::\n\n## Creating a suitable model\n\nSo far we've established that using a simple linear model describe a potential relationship between `glucose` levels and the probability of getting a positive test result is not a good idea. So, what _can_ we do?\n\nOne of the ways we can deal with binary outcome data is by performing a logistic regression. Instead of fitting a straight line to our data, and performing a regression on that, we fit a line that has an S shape. This avoids the model making predictions outside the $[0, 1]$ range.\n\nThere are many mathematical functions that produce S-shaped graphs. The **logistic function** is one of them and well-suited to these kind of data.\n\nIn the most simple form a logistic function is written like this:\n\n$Y = \\frac{1}{1 + \\exp(-X)}$\n\n:::{.callout-important}\n## Euler's number\n\nIn mathematics, $\\rm e$ represents a constant of around 2.718. Another notation is $\\exp$, which is often used when notations become a bit cumbersome. Here, I exclusively use the $\\exp$ notation for consistency.\n:::\n\nWe can _generalise_ this, by writing it as follows:\n\n$Y = \\frac{1}{1 + \\exp-(\\beta_0 + \\beta_1X)}$\n\nNote that the $\\beta_0 + \\beta_1X$ part is identical to the formula of a straight line. We've come across this before when we were doing simple linear regression!\n\nThe rest of the function is what makes the straight line curve into its characteristic S shape. The middle of the S (where $Y = 0.5$) occurs when $X = \\frac{-b}{a}$.\n\n::: {.callout-important}\n## The logistic function\n\nThe shape of the logistic function is hugely influenced by the different parameter, in particular $\\beta_1$. The plots below show different situations, where $\\beta_0 = 0$ in all cases, but $\\beta_1$ varies.\n\nThe first plot shows the logistic function in its simplest form, with the others showing the effect of varying $\\beta_1$.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm-practical-logistic-binary_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n* when $\\beta_1 = 1$, this gives the simplest logistic function\n* when $\\beta_1 = 0$ gives a horizontal line, with $Y = 1/(1+\\exp(-\\beta_0X)$\n* when $\\beta_1$ is negative flips the curve around, so it slopes down\n* when $\\beta_1$ is very large then the curve becomes extremely steep\n:::\n\nWe can fit such an S-shaped curve to our `diabetes` data set, by creating a generalised linear model.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nIn R we have a few options to do this, and by far the most familiar function would be `glm()`. Here we save the model in an object called `glm_dia`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_dia <- glm(test_result ~ glucose,\n               family = binomial,\n               data = diabetes)\n```\n:::\n\n\nThe format of this function is similar to that used by the `lm()` function for linear models. The important difference is that we must specify the _family_ of error distribution to use. For logistic regression we must set the family to **binomial**.\n\nIf you forget to set the `family` argument, then the `glm()` function will perform a standard linear model fit, identical to what the `lm()` function would do.\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# create a linear model\nmodel = smf.glm(formula= \"test_result ~ glucose\",\n                family = sm.families.Binomial(),\n                data = diabetes_py)\n# and get the fitted parameters of the model\nglm_dia_py = model.fit()\n```\n:::\n\n\n:::\n\n## Model output\n\nThat's the easy part done! The trickier part is interpreting the output. First of all, we'll get some summary information.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(glm_dia)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = test_result ~ glucose, family = binomial, data = diabetes)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1353  -0.7819  -0.5189   0.8269   2.2832  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -5.611732   0.442289  -12.69   <2e-16 ***\nglucose      0.039510   0.003398   11.63   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 936.6  on 727  degrees of freedom\nResidual deviance: 752.2  on 726  degrees of freedom\nAIC: 756.2\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(glm_dia_py.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:            test_result   No. Observations:                  728\nModel:                            GLM   Df Residuals:                      726\nModel Family:                Binomial   Df Model:                            1\nLink Function:                  Logit   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -376.10\nDate:                Mon, 06 Feb 2023   Deviance:                       752.20\nTime:                        11:08:50   Pearson chi2:                     713.\nNo. Iterations:                     4   Pseudo R-squ. (CS):             0.2238\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -5.6117      0.442    -12.688      0.000      -6.479      -4.745\nglucose        0.0395      0.003     11.628      0.000       0.033       0.046\n==============================================================================\n```\n:::\n:::\n\n\n:::\n\nThere’s a lot to unpack here so take a deep breath (or make sure you have a coffee) before continuing...\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n* The first lines just confirm which model we’ve been fitting (trust me, this can be useful when you’re in the middle of a load of analysis and you’ve lost track of what the hell is going on!)\n* The next block is called Deviance Residuals. This isn’t particularly useful, but just so you know: for linear models the residuals were calculated for each data point and then squared and added up to get the `SS` (sum of squares), which is used to fit the model. For generalised linear models we don’t use SS to fit the model and instead we use an entirely different method called maximum likelihood. This fitting procedure generates a different quantity, called Deviance, which is the analogue of SS. A deviance of zero indicates the best model we could hope for and bigger values indicate a model that doesn’t fit quite as well. The deviance residuals are then values associated with each data point, that when squared and summed give the deviance for the model (an exact analogy to normal residuals). You’re unlikely to ever need to know this, but I had some time on my hands and decided to share this little nugget with you :-)\n*\tThe `Coefficients` block is next. The main numbers to extract from the output are the two numbers underneath `Estimate.Std`:\n\n```\n(Intercept)  -5.611732\nglucose      0.039510\n```\n\n## Python\n\nThe top part of table contains a lot of information about the model we’ve just created at a high level. The left-hand column just tells us a lot of stuff that we really don’t care about like:\n\n* the name of the dependent variable (which we already know because we entered it ourselves!);\n* the type of model (a binomial glm which we again already knew).\n* the type of link function (in this case a logit link – we don’t really care\nabout this either).\n* Generalized Linear Models don’t have exact analytical methods for\nfitting to the data and they all use some form of iterative algorithm. In this case we used the standard method called Iteratively Reweighted Least Squares (IRLS),\n* and the model took 4 iterations to converge.\n* This left-hand column also helpfully tells us the time and date when the\nanalysis was carried out – how helpful!\n\nThe right-hand column starts to give us some more useful summary statistics\nthat we’ll end up using. In particular we care about the Deviance value. For linear models the residuals were calculated for each data point and then squared and added up to get the SS (sum of squares), which is used to fit the model. For generalised linear models we don’t use SS to fit the model and instead we use an entirely different method called maximum likelihood. This fitting procedure generates a different quantity, called Deviance, which is the analogue of SS. A deviance of zero indicates the best model we could hope for (basically that the model completely matches the data) and bigger values indicate a model that doesn’t fit quite as well. We’ll also need the Df residuals value here (degrees of freedom) for some later calculations.\n\nRight at the bottom is a table showing the model coefficients. The main numbers to extract from the output are the two numbers in the `coef` column:\n\n```\n======================\n                 coef\n----------------------\nIntercept     -5.6117\nglucose        0.0395\n======================\n```\n\n:::\n\nThese are the coefficients of the logistic model equation and need to be placed in the correct equation if we want to be able to actually calculate the probability of having a positive diabetes test for a given glucose level.\n\nThe p values (`Pr(>|z|`) at the end of each coefficient row merely show whether that particular coefficient is significantly different from zero. This is similar to the p-values obtained in the summary output of a linear model, and as before, for continuous predictors in simple models these p-values can be used to decide whether that predictor is important (so in this case glucose appears to be significant). However, these p-values aren’t great when we have multiple predictor variables, or when we have categorical predictors with multiple levels (since the output will give us a p-value for each level rather than for the predictor as a whole).\n\nWe can use the coefficients to actually calculate the probability of having a positive diabetes test for a given glucose level:\n\n$$ P(positive \\ test\\ result) = \\frac{\\exp(-5.61 + 0.04 \\times glucose)}{1 + \\exp(-5.61 + 0.04 \\times glucose)} $$\n\n::: {.callout-note collapse=\"true\"}\n## Expanded explanation\n\nWe started with:\n\n-   Our linear predictor equation $$logit(p) = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p$$\n\n-   and link function $$logit(p) = log(\\frac{p}{1 - p})$$\n\nOur coefficients are as follows:\n\n| coefficient | value                                                                       |\n|:-----------------------------------|:-----------------------------------|\n| $\\beta_0$   | -5.6117317 |\n| $\\beta_1$   | 0.0395101     |\n\nWhich means that we can write the linear predictor equation as follows:\n\n$$logit(p) = -5.61 + 0.04 \\times glucose$$ We still have to take into account our link function. Combining the two equations gives us:\n\n$$log(\\frac{p}{1 - p}) = -5.61 + 0.04 \\times glucose$$\n\nTo get our $p$ (the probability of a person having a positive diabetes test result), we need to exponentiate our equation:\n\n$$\\frac{p}{1 - p} = \\exp{(-5.61 + 0.04 \\times glucose)}$$\n\nleading to...\n\n$$p = \\frac{\\exp{(-5.61 + 0.04 \\times glucose)}}{1 + \\exp{(-5.61 + 0.04 \\times glucose)}}$$\n:::\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n* The next line tells us that the dispersion parameter was assumed to be 1 for this binomial model. Dispersion is a property that says whether the data were more or less spread out around the logistic curve than we would expect. A dispersion parameter of 1 says that the data are spread out exactly as we would expect. Greater than 1 is called over-dispersion and less than 1 is called under-dispersion. Here this line is saying that when we fitted this model, we were assuming that the dispersion of the data was exactly 1. For binary data, like we have here, the data cannot be over or under-dispersed but this is something that we’ll need to check for other sorts of glms.\n\nThe last three lines relate to quantities called deviance and AIC (Akaike Information Criterion).\n\nAs we said just above, the deviance values are the equivalent of Sums of Squares values in linear models (and are a product of the technique used to fit the curve to the data). They can be used as a metric of goodness of fit for the model, with a deviance of 0 indicating a perfect fitting model. The deviance for the null model (i.e. the model without any predictors, basically saying that the probability of getting a positive diabetes score is constant and doesn’t depend on glucose level) is given by the first line and the deviance for the actual model is given by the residual deviance line. We will see how we can use the deviance to do two things.\n\n1. to check of whether the model is actually any good (i.e. does it in any way look like it’s close to the data). This is akin to what we were doing with $R^2$ values in linear models.\n2. to check if the model we’ve specified is better than the null model.\n\nIt’s important to realise that these two things can be independent of each other; we can have a model that is significantly better than a null model whilst still being rubbish overall (the null model will have been even more rubbish in comparison), and we can have a model that is brilliant yet still not be better than the null model (in this case the null model was already brilliant).\n\nAs we found in the [model comparisons practical](https://cambiotraining.github.io/corestats/materials/cs5_practical_model-comparisons.html), the AIC value is meaningless by itself, but it will allow us to compare this model to another model with different terms (with the model with the smaller AIC value being the better fitting model).\n:::\n\n\n## Exercise\n\n::: {.callout-tip collapse=\"true\"}\n## Answer\n::: {.panel-tabset group=\"language\"}\n## R\n## Python\n:::\n:::\n\n## Key points\n\n::: {.callout-note}\n-   We use a logistic regression to model a binary response\n-   We can feed new observations into the model and get probabilities for the outcome\n:::\n",
    "supporting": [
      "glm-practical-logistic-binary_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}