{
  "hash": "34d29200178c58dfd012323130895825",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Analysing count data\"\nlightbox: true\nformat: html\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n::: callout-tip\n## Learning outcomes\n\n-   Be able to identify count data\n-   Fit a Poisson regression model with count data\n-   Assess whether assumptions are met and test significance of the model\n:::\n\n## Context\nWe have now covered analysing binary responses and learned how to assess the quality and appropriateness of the resulting models. In the next sections we extend this further, by looking at a different type of response variable: count data. The humble count may look innocent, but often hides a whole lot of nuances that are hard to spot. So, pay attention!\n\n## Section setup\n\n:::: {.callout-note collapse=\"true\"}\n## Click to expand\n\nWe'll use the following libraries and data:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required R libraries\nlibrary(tidyverse)\nlibrary(performance)\n\n# Read in the required data\nislands <- read_csv(\"data/islands.csv\")\nseatbelts <- read_csv(\"data/seatbelts.csv\")\n```\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Load required Python libraries\nimport pandas as pd\nimport math\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.stats import *\nfrom plotnine import *\n\n# Read in the required data\nislands = pd.read_csv(\"data/islands.csv\")\nseatbelts = pd.read_csv(\"data/seatbelts.csv\")\n```\n:::\n\n:::\n::::\n\nThe worked example in this chapter will use the `islands` dataset.\n\nThis is a dataset comprising 35 observations of two variables. For each small island in the dataset, the researcher recorded the number of unique `species`; they want to know if this can be predicted from the `area` (km<sup>2</sup>) of the island.\n\n## Load and visualise the data\n\nFirst we load the data, then we visualise it.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nislands <- read_csv(\"data/islands.csv\")\n\nhead(islands)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  species  area\n    <dbl> <dbl>\n1     114  12.1\n2     130  13.4\n3     113  13.7\n4     109  14.5\n5     118  16.8\n6     136  19.0\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nislands = pd.read_csv(\"data/islands.csv\")\n\nislands.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   species       area\n0      114  12.076133\n1      130  13.405439\n2      113  13.723525\n3      109  14.540359\n4      118  16.792122\n```\n\n\n:::\n:::\n\n:::\n\nWe can plot the data:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(islands, aes(x = area, y = species)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![Scatterplot of area and species](glm-12-analysing-count-data_files/figure-html/fig-scatter_isl-1.png){#fig-scatter_isl width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(islands, aes(x = \"area\", y = \"species\")) +\n   geom_point())\n\np.show()\n```\n\n::: {.cell-output-display}\n![Scatterplot of area and species](glm-12-analysing-count-data_files/figure-html/fig-scatter_isl_py-1.png){#fig-scatter_isl_py width=614}\n:::\n:::\n\n:::\n\nEach dot on the scatterplot represents an island in the dataset.\n\nIt looks as though `area` definitely has some relationship with the number of `species` that we observe.\n\nNext step is to try to model these data.\n\n## Constructing a model\n\nThe `species` variable is the outcome or response (since we're interested in whether it's predicted by `area`).\n\nIt qualifies as a count variable. It's bounded at 0 and $\\infty$, and can only jump up in integers - in other words, you can't have less than 0 species, or 6.3 species.\n\nThis means the best place to start is a Poisson regression. We fit these in a very similar way to a logistic regression, just with a different option specified for the `family` argument.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_isl <- glm(species ~ area,\n               data = islands, family = \"poisson\")\n```\n:::\n\n\nand we look at the model summary:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(glm_isl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = species ~ area, family = \"poisson\", data = islands)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) 4.241129   0.041322  102.64   <2e-16 ***\narea        0.035613   0.001247   28.55   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 856.899  on 34  degrees of freedom\nResidual deviance:  30.437  on 33  degrees of freedom\nAIC: 282.66\n\nNumber of Fisher Scoring iterations: 3\n```\n\n\n:::\n:::\n\n\nThe output is strikingly similar to the logistic regression models (who’d have guessed, eh?) and the main numbers to extract from the output are the coefficients (the two numbers underneath `Estimate` in the table above):\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefficients(glm_isl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)        area \n 4.24112904  0.03561346 \n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel = smf.glm(formula = \"species ~ area\",\n                family = sm.families.Poisson(),\n                data = islands)\n\nglm_isl = model.fit()\n```\n:::\n\n\nLet's look at the model output:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(glm_isl.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                species   No. Observations:                   35\nModel:                            GLM   Df Residuals:                       33\nModel Family:                 Poisson   Df Model:                            1\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -139.33\nDate:                Fri, 25 Jul 2025   Deviance:                       30.437\nTime:                        08:28:46   Pearson chi2:                     30.3\nNo. Iterations:                     4   Pseudo R-squ. (CS):              1.000\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      4.2411      0.041    102.636      0.000       4.160       4.322\narea           0.0356      0.001     28.551      0.000       0.033       0.038\n==============================================================================\n```\n\n\n:::\n:::\n\n\nThe output is strikingly similar to the logistic regression models (who’d have guessed, eh?) and the main numbers to extract from the output are the coefficients (the two numbers underneath `coef` in the table above):\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(glm_isl.params)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIntercept    4.241129\narea         0.035613\ndtype: float64\n```\n\n\n:::\n:::\n\n:::\n\n### The model equation\n\nNow that we have the beta coefficients, we can place them inside an equation.\n\nThe left-hand side of this equation is the expected number of species, $E(species)$.\n\nOn the right-hand side, we take the linear equation $\\beta_0 + \\beta_1 * x_1$ and embed it inside the inverse link function, which in this case is just the exponential function.\n\n\n::: {.cell}\n\n:::\n\n\nIt looks like this:\n\n$$ E(species) = \\exp(4.24 + 0.036 \\times area) $$\n\nInterpreting this requires a bit of thought (not much, but a bit).\n\nThe intercept coefficient, 4.24, is related to the number of species we would expect on an island of zero area. But in order to turn this number into something meaningful we have to exponentiate it.\n\nSince $\\exp(4.24) \\approx 69$, we can say that the baseline number of species the model expects on any island is 69.\n\nThe coefficient of `area` is the fun bit. For starters we can see that it is a positive number which does mean that increasing `area` leads to increasing numbers of `species`. Good so far.\n\nBut what does the value 0.036 actually mean? Well, if we exponentiate it as well, we get $\\exp(0.036) \\approx 1.04$. This means that for every increase in `area` of 1 km<sup>2</sup> (the original units of the area variable), the number of species on the island is multiplied by 1.04.\n\nSo, an island of area km<sup>2</sup> will have $1.04 \\times 69 \\approx 72$ species.\n\n## Plotting the Poisson regression\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(islands, aes(area, species)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", se = FALSE, fullrange = TRUE, \n              method.args = list(family = \"poisson\")) +\n  xlim(10,50)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Poisson regression on `species ~ area`](glm-12-analysing-count-data_files/figure-html/fig-poisson_isl-1.png){#fig-poisson_isl width=672}\n:::\n:::\n\n\n## Python\n\nFirst, we produce a set of predictions, which we can then plot.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel = pd.DataFrame({'area': list(range(10, 50))})\n\nmodel[\"pred\"] = glm_isl.predict(model)\n\nmodel.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   area        pred\n0    10   99.212463\n1    11  102.809432\n2    12  106.536811\n3    13  110.399326\n4    14  114.401877\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(islands, aes(x = \"area\", y = \"species\")) +\n   geom_point() +\n   geom_line(model, aes(x = \"area\", y = \"pred\"),\n                        colour = \"blue\", size = 1))\n\np.show()\n```\n\n::: {.cell-output-display}\n![Poisson regression on `species ~ area`](glm-12-analysing-count-data_files/figure-html/fig-poisson_isl_py-1.png){#fig-poisson_isl_py width=614}\n:::\n:::\n\n:::\n\n## Assumptions & model fit\n\nAs a reminder from last chapter, we want to consider the following things to assess whether we've fit the right model:\n\n-   The distribution of the response variable\n-   The link function\n-   Independence\n-   Influential points\n\n(We don't need to worry about collinearity here - there's only one predictor!)\n\nWe're also going to talk about **dispersion**, which really comes into play when talking about count data - we'll get to that after we've run through the stuff that's familiar.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWith the generic `check_model` function, we can visually assess a few things quite quickly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(glm_isl)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Diagnostic plots for `glm_isl`](glm-12-analysing-count-data_files/figure-html/fig-diag_glm_isl-3.png){#fig-diag_glm_isl width=672}\n:::\n:::\n\n\nThe posterior predictive check looks alright. The blue simulations seem to be following a pretty similar distribution to the actual data in green.\n\nThe leverage/Cook's distance plot also isn't identifying any data points that we need to be concerned about. We can follow up on that:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_outliers(glm_isl, threshold = list('cook'=0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.5).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n## Python\n\nWe can check for influential points:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ninfluence = glm_isl.get_influence()\n\ncooks = influence.cooks_distance[0]\ninfluential_points = np.where(cooks > 0.5)[0]\n\nprint(\"Influential points:\", influential_points)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluential points: []\n```\n\n\n:::\n:::\n\n:::\n\n**Influential points**: There's no evidence of any points with high Cook's distances, so life is rosy on that front.\n\n**Independence**: From the description of the dataset, it sounds plausible that each island is independent. Of course, if we later found out that some of the islands were clustered together into a bunch of archipelagos, that would definitely be cause for concern.\n\n**Distribution & link function**: Again, from the description of the `species` variable, we can be confident that this really is a count variable. Whether or not Poisson regression with the log link function is correct, however, will depend on what happens when we look at the dispersion parameter.\n\n## Dispersion {#sec-mat_dispersion}\n\n### What is dispersion?\n\nDispersion, in statistics, is a general term to describe the variability, scatter, or spread of a distribution. Variance is actually a type of dispersion.\n\nIn a normal distribution, the mean (average/central tendency) and the variance (dispersion) are independent of each other; we need both numbers, or parameters, to understand the shape of the distribution.\n\nOther distributions, however, require different parameters to describe them in full. For a Poisson distribution - which we’ll learn more about when we talk about count data - we need just one parameter ($\\lambda$) to describe the distribution, because the mean and variance are assumed to be the same.\n\nIn the context of a model, you can think about the dispersion as the degree to which the data are spread out around the model curve. A dispersion parameter of 1 means the data are spread out exactly as we expect; \\<1 is called underdispersion; and \\>1 is called overdispersion.\n\n### A \"hidden assumption\"\n\nWhen performing Poisson regression, we make an extra assumption: that the dispersion parameter to 1. This means we don't have to waste time and statistical power in estimating the dispersion.\n\nHowever, if our data are underdispersed or overdispersed, then we might be violating this assumption we've made.\n\nUnderdispersion is quite rare. It's far more likely that you'll encounter overdispersion.\n\nIn these situations, you may wish to fit a different GLM to the data. Negative binomial regression, for instance, is a common alternative for count data.\n\n### Assessing dispersion\n\nThe easiest way to check dispersion in a model is to calculate the ratio of the residual deviance to the residual degrees of freedom.\n\nIf we take a look at the model output, we can see the two quantities we care about - residual deviance and residual degrees of freedom:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(glm_isl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = species ~ area, family = \"poisson\", data = islands)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) 4.241129   0.041322  102.64   <2e-16 ***\narea        0.035613   0.001247   28.55   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 856.899  on 34  degrees of freedom\nResidual deviance:  30.437  on 33  degrees of freedom\nAIC: 282.66\n\nNumber of Fisher Scoring iterations: 3\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(glm_isl.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                species   No. Observations:                   35\nModel:                            GLM   Df Residuals:                       33\nModel Family:                 Poisson   Df Model:                            1\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -139.33\nDate:                Fri, 25 Jul 2025   Deviance:                       30.437\nTime:                        08:28:47   Pearson chi2:                     30.3\nNo. Iterations:                     4   Pseudo R-squ. (CS):              1.000\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      4.2411      0.041    102.636      0.000       4.160       4.322\narea           0.0356      0.001     28.551      0.000       0.033       0.038\n==============================================================================\n```\n\n\n:::\n:::\n\n:::\n\nThe residual deviance is 30.44, on 33 residual degrees of freedom. All we need to do is divide one by the other to get our dispersion parameter.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_isl$deviance/glm_isl$df.residual\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.922334\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(glm_isl.deviance/glm_isl.df_resid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.9223340414458482\n```\n\n\n:::\n:::\n\n:::\n\nThe dispersion parameter here is 0.9223. That's pretty good - not far off 1 at all.\n\nBut how can we check whether it is *significantly* different from 1?\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nOnce again, the `performance` package comes in very helpful here.\n\nThe `check_overdispersion` function will give us both the dispersion parameter and a p-value (which is based on a chi-square test - like the goodness-of-fit ones you were running [last chapter](glm-09-significance-testing.qmd)).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_overdispersion(glm_isl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Overdispersion test\n\n       dispersion ratio =  0.919\n  Pearson's Chi-Squared = 30.339\n                p-value =    0.6\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNo overdispersion detected.\n```\n\n\n:::\n:::\n\n\nHere, it confirms our suspicions; the dispersion parameter is both *descriptively* close to 1, and also not *significantly* different from 1.\n\nYou'll notice that this function does give a slightly different value for the dispersion parameter, compared to when we calculated it manually above.\n\nThis is because it actually uses the sum of squared Pearson residuals instead of the residual deviance (a distinction which really isn't worth worrying about). Broadly, the conclusion should be the same, so the difference doesn't matter very much.\n\n## Python\n\nWell, you've actually already got the knowledge you need to do this, from the [previous chapter](glm-09-significance-testing.qmd) on significance testing.\n\nSpecifically, the chi-squared goodness-of-fit test can be used to check whether the dispersion is within sensible limits.\n\n\n::: {.cell}\n\n```{.python .cell-code}\npvalue = chi2.sf(glm_isl.deviance, glm_isl.df_resid)\n\nprint(pvalue)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.5953470127463268\n```\n\n\n:::\n:::\n\n\nIf our chi-squared goodness-of-fit test returns a large (insignificant) p-value, as it does here, that tells us that we don't need to worry about the dispersion.\n\nIf our chi-squared goodness-of-fit test returned a small, significant p-value, this would tell us our model doesn't fit the data well. And, since dispersion is all about the spread of points around the model, it makes sense that these two things are so closely related!\n:::\n\nGreat - we can proceed with the Poisson regression, since we don't seem to have overdispersed or underdispersed data.\n\n[Next chapter](glm-13-overdispersed-count-data.qmd) we'll look at what we would have done next, if we had run into problems with dispersion.\n\n## Assessing significance\n\nBy testing the dispersion with a chi-square test, we have already essentially checked the goodness-of-fit of this model - it's good.\n\nThis leaves us with two things to check:\n\n1.  Is the overall model better than the null model?\n2.  Are any of the individual predictors significant?\n\n### Comparing against the null\n\nWe need to fit the null model, and then we can extract the null deviance and degrees of freedom to compare against our model.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_isl_null <- glm(species ~ 1,\n                    data = islands, family = \"poisson\")\n\nanova(glm_isl, glm_isl_null)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel 1: species ~ area\nModel 2: species ~ 1\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1        33      30.44                          \n2        34     856.90 -1  -826.46 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nSince there's only one predictor, we actually could achieve the same effect here by just computing an analysis of deviance table:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(glm_isl, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: species\n\nTerms added sequentially (first to last)\n\n     Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \nNULL                    34     856.90              \narea  1   826.46        33      30.44 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n## Python\n\nFirst, we fit a null model:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel = smf.glm(formula = \"species ~ 1\",\n                family = sm.families.Poisson(),\n                data = islands)\n                \nglm_isl_null = model.fit()\n\nglm_isl_null.df_resid\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nnp.int64(34)\n```\n\n\n:::\n:::\n\n\nAnd now we can compare the two:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Calculate the likelihood ratio (i.e. the chi-square value)\nlrstat = -2*(glm_isl_null.llf - glm_isl.llf)\n\n# Calculate the associated p-value\npvalue = chi2.sf(lrstat, glm_isl_null.df_resid - glm_isl.df_resid)\n\nprint(lrstat, pvalue)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n826.4623291533155 9.523357725017566e-182\n```\n\n\n:::\n:::\n\n:::\n\nThis gives a reported p-value extremely close to zero, which is rather small.\n\nTherefore, this model is significant over the null, and `species` does appear to be predicted by `area`.\n\n## Exercises\n\n### Seat belts {#sec-exr_seatbelts}\n\n::::::::::: {.callout-exercise #ex-seatbelts}\n#### Seat belts\n\n{{< level 2 >}}\n\nFor this exercise we'll be using the data from `data/seatbelts.csv`.\n\nThe data tracks the number of drivers killed in road traffic accidents, before and after the seat belt law was introduced. The information on whether the law was in place is encoded in the `law` column as `0` (law not in place) or `1` (law in place).\n\nThe `year` variable is our predictor of interest.\n\nIn this exercise, you should:\n\n1.  Visualise the data\n2.  Create a poisson regression model and extract its equation\n3.  Plot the regression model on top of the data\n4.  Assess if the model is a decent predictor for the number of fatalities (& check assumptions)\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseatbelts <- read_csv(\"data/seatbelts.csv\")\n\nhead(seatbelts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 10\n  casualties drivers front  rear   kms petrol_price van_killed   law  year month\n       <dbl>   <dbl> <dbl> <dbl> <dbl>        <dbl>      <dbl> <dbl> <dbl> <chr>\n1        107    1687   867   269  9059        0.103         12     0  1969 Jan  \n2         97    1508   825   265  7685        0.102          6     0  1969 Feb  \n3        102    1507   806   319  9963        0.102         12     0  1969 Mar  \n4         87    1385   814   407 10955        0.101          8     0  1969 Apr  \n5        119    1632   991   454 11823        0.101         10     0  1969 May  \n6        106    1511   945   427 12391        0.101         13     0  1969 Jun  \n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nseatbelts = pd.read_csv(\"data/seatbelts.csv\")\n\nseatbelts.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   casualties  drivers  front  rear  ...  van_killed  law  year  month\n0         107     1687    867   269  ...          12    0  1969    Jan\n1          97     1508    825   265  ...           6    0  1969    Feb\n2         102     1507    806   319  ...          12    0  1969    Mar\n3          87     1385    814   407  ...           8    0  1969    Apr\n4         119     1632    991   454  ...          10    0  1969    May\n\n[5 rows x 10 columns]\n```\n\n\n:::\n:::\n\n:::\n\n::::::::: {.callout-answer collapse=\"true\"}\n#### Visualise the data\n\nFirst we have a look at the data comparing no law versus law:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe have to convert the `law` column to a factor, otherwise R will see it as numerical.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseatbelts |> \n  ggplot(aes(as_factor(law), casualties)) +\n   geom_boxplot() +\n   geom_jitter(width = 0.2)\n```\n\n::: {.cell-output-display}\n![Boxplot of driver casualties before and after seatbelt introduction](glm-12-analysing-count-data_files/figure-html/fig-boxplot_seatbelt-1.png){#fig-boxplot_seatbelt width=672}\n:::\n:::\n\n\nThe data are recorded by month and year, so we can also display the number of drivers killed by year:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseatbelts |> \n  ggplot(aes(year, casualties)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![Scatterplot of driver casualties across years](glm-12-analysing-count-data_files/figure-html/fig-scatter_seatbelt-1.png){#fig-scatter_seatbelt width=672}\n:::\n:::\n\n\n## Python\n\nWe have to convert the `law` column to a factor, otherwise R will see it as numerical.\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(seatbelts, aes(x = seatbelts.law.astype(object),\n                       y = \"casualties\")) +\n   geom_boxplot() +\n   geom_jitter(width = 0.2))\n\np.show()\n```\n\n::: {.cell-output-display}\n![Boxplot of driver casualties before and after seatbelt introduction](glm-12-analysing-count-data_files/figure-html/fig-boxplot_seatbelt_py-1.png){#fig-boxplot_seatbelt_py width=614}\n:::\n:::\n\n\nThe data are recorded by month and year, so we can also display the number of casualties by year:\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(seatbelts,\n         aes(x = \"year\",\n             y = \"casualties\")) +\n     geom_point())\n\np.show()\n```\n\n::: {.cell-output-display}\n![Scatterplot of driver casualties across years](glm-12-analysing-count-data_files/figure-html/fig-scatter_seatbelt_py-3.png){#fig-scatter_seatbelt_py width=614}\n:::\n:::\n\n:::\n\nThe data look a bit weird. There's a bit of a wavy pattern across years. And although it looks like fatalities are lower after the law was implemented, there are many more observations when the law was *not* in place, which is going to make the data harder to interpret.\n\n#### Constructing a model\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_stb <- glm(casualties ~ year,\n               data = seatbelts, family = \"poisson\")\n```\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel = smf.glm(formula = \"casualties ~ year\",\n                family = sm.families.Poisson(),\n                data = seatbelts)\n\nglm_stb = model.fit()\n```\n:::\n\n:::\n\n#### Model equation\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefficients(glm_stb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)        year \n  37.168958   -0.016373 \n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(glm_stb.params)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIntercept    37.168958\nyear         -0.016373\ndtype: float64\n```\n\n\n:::\n:::\n\n:::\n\nThe coefficients of the Poisson model equation should be placed in the following formula, in order to estimate the expected number of species as a function of island size:\n\n$$ E(casualties) = \\exp(37.17 - -0.016 \\times year) $$\n\n#### Visualise model\n\nWe can just adapt the code used in the worked example earlier in the chapter:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(seatbelts, aes(year, casualties)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", se = FALSE, fullrange = TRUE, \n              method.args = list(family = poisson)) +\n  xlim(1970, 1985)\n```\n\n::: {.cell-output-display}\n![Poisson regression of driver casualties across years](glm-12-analysing-count-data_files/figure-html/fig-poisson_seatbelt-1.png){#fig-poisson_seatbelt width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel = pd.DataFrame({'year': list(range(1968, 1985))})\n\nmodel[\"pred\"] = glm_stb.predict(model)\n\nmodel.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   year        pred\n0  1968  140.737690\n1  1969  138.452153\n2  1970  136.203733\n3  1971  133.991827\n4  1972  131.815842\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(seatbelts, aes(x = \"year\",\n                       y = \"casualties\")) +\n   geom_point() +\n   geom_line(model, aes(x = \"year\", y = \"pred\"),\n                        colour = \"blue\", size = 1))\n\np.show()\n```\n\n::: {.cell-output-display}\n![Poisson regression of driver casualties across years](glm-12-analysing-count-data_files/figure-html/fig-poisson_seatbelt_py-1.png){#fig-poisson_seatbelt_py width=614}\n:::\n:::\n\n:::\n\n#### Assessing model quality & significance\n\nAre the assumptions met?\n\n|                                       |                              |\n|---------------------------------------|------------------------------|\n| Response distribution & link function | Yes, based on the info given |\n| Independence                          | Yes, based on the info given |\n| Influential points                    | Check with Cook's distance   |\n| Dispersion                            | Check dispersion parameter   |\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe can assess outliers visually or by printing a list of high leverage points:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_outliers(glm_stb, threshold = list('cook'=0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.5).\n- For variable: (Whole model)\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_model(glm_stb, check = 'outliers')\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-12-analysing-count-data_files/figure-html/unnamed-chunk-45-3.png){width=672}\n:::\n:::\n\n\nIt seems we're okay on the outlier front.\n\nFor dispersion, again we have some options of how to test it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_overdispersion(glm_stb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Overdispersion test\n\n       dispersion ratio =   4.535\n  Pearson's Chi-Squared = 861.667\n                p-value = < 0.001\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nOverdispersion detected.\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_model(glm_stb, check = 'overdispersion')\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-12-analysing-count-data_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n:::\n\n\nDispersion is *definitely* a problem here.\n\nFor completeness, we can also peek at the posterior predictive check:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(glm_stb, check = 'pp_check')\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `glm`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-12-analysing-count-data_files/figure-html/unnamed-chunk-47-1.png){width=672}\n:::\n:::\n\n\nIt doesn't seem to be doing the best job. Around 0 and in the 180+ range of the x-axis, it's under-predicting the counts; and it might be over-predicting a bit in the middle (120-140 ish).\n\n## Python\n\nWe can assess outliers by printing a list of high leverage points:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ninfluence = glm_isl.get_influence()\n\ncooks = influence.cooks_distance[0]\ninfluential_points = np.where(cooks > 0.5)[0]\n\nprint(\"Influential points:\", influential_points)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluential points: []\n```\n\n\n:::\n:::\n\n\nIt seems we're okay on the outlier front.\n\nFor dispersion, let's calculate the parameter and p-value:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npvalue = chi2.sf(glm_stb.deviance, glm_stb.df_resid)\n\nprint(glm_stb.deviance/glm_stb.df_resid, pvalue)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n4.475851158209689 3.1298697149299994e-84\n```\n\n\n:::\n:::\n\n\nDispersion is *definitely* a problem here.\n:::\n\n|                                       |                                |\n|---------------------------------------|--------------------------------|\n| Response distribution & link function | Yes, based on the info given   |\n| Independence                          | Yes, based on the info given   |\n| Influential points                    | Yes, no data points identified |\n| Dispersion                            | **Clear overdispersion**       |\n\nGiven that we have a problem with overdispersion, we probably wouldn't proceed with significance testing here under normal circumstances. Instead, we'd want to fit a different GLM that can handle this overdispersion.\n\nFor completeness, however, since these are course materials rather than normal circumstances - let's check: is the model significant over the null?\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_null <- glm(casualties ~ 1, \n                family = \"poisson\", \n                data = seatbelts)\n\nanova(glm_stb, glm_null)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel 1: casualties ~ year\nModel 2: casualties ~ 1\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1       190     850.41                          \n2       191     984.50 -1  -134.08 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel = smf.glm(formula = \"casualties ~ 1\",\n                family = sm.families.Poisson(),\n                data = seatbelts)\n\nglm_stb_null = model.fit()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlrstat = -2*(glm_stb_null.llf - glm_stb.llf)\npvalue = chi2.sf(lrstat, glm_stb_null.df_resid - glm_stb.df_resid)\n\nprint(lrstat, pvalue)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n134.0834016068129 5.23879166948147e-31\n```\n\n\n:::\n:::\n\n:::\n\nWhat does the significant p-value here tell us?\n\nWell, given the difference in degrees of freedom (1), the change in residual deviance between our model and the null model is unexpectedly large. So the model is doing *something* over and above what the null is doing.\n\n#### Conclusions\n\nDoes this significant comparison against the null allow us to draw any conclusions about whether the seatbelt `law` affects the number of `casualties`?\n\nNo. Don't let it tempt you.\n\nThe model we've constructed here is not a good fit and doesn't meet all of the assumptions. We need to fit a different type of model that can cope with the overdispersion, which we'll look into next chapter.\n:::::::::\n:::::::::::\n\n## Summary\n\n::: callout-tip\n\n#### Key points\n\n-   Count data are bounded between 0 and $\\infty$, with integer increases\n-   This type of data can be modelled with a Poisson regression, using a log link function\n-   Poisson regression makes all of the same assumptions as logistic regression, plus an assumption about dispersion\n:::\n",
    "supporting": [
      "glm-12-analysing-count-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}