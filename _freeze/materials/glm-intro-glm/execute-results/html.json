{
  "hash": "171995b17868dc6e119e3795bca553b0",
  "result": {
    "markdown": "---\ntitle: \"Generalising your model\"\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n## Putting the \"G\" into GLM\n\nIn the previous linear model example all the assumptions were met. But what if we have data where that isn't the case? For example, what if we have data where we _can't_ describe the relationship between the predictor and response variables in a linear way?\n\nOne of the ways we can deal with this is by using a **generalised linear model**, also abbreviated as GLM. In a way it's an extension of the linear model we discussed in the previous section. As with the normal linear model, the predictor variables in the model are in a linear combination, such as:\n\n$$\n\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_3 + ...\n$$\n\nHere, the $\\beta_0$ value is the constant or intercept, whereas each subsequent $\\beta_i$ is a unique regression coefficient for each $X_i$ predictor variable. So far so good.\n\nHowever, the GLM makes the linear model more flexible in two ways:\n\n:::.{callout-important}\n1. In a standard linear model the linear combination (e.g. like we see above) becomes the predicted outcome value. With a GLM a transformation is specified, which turns the linear combination into the predicted outcome value. This is called a **link function**.\n2. A standard linear model assumes a continuous, normally distributed outcome, whereas **with GLM the outcome can be both continuous or integer**. Furthermore, the outcome does not have to be normally distributed. Indeed, **the outcome can follow a different kind of distribution**, such as binomial, Poisson, exponential etc.\n:::\n\nWe'll introduce each of these elements below, then illustrate how they are used in practice, using different types of data.\n\nThe link function and different distributions are closely...err, _linked_. So in order to make sense of what the link function is doing, it's useful to understand better the different distributional assumptions. So we'll start with those.\n\n## Distributions\n\nIn the examples of a linear model we've seen that the residuals needed to be normally distributed. We've mainly used the Q-Q plot to assess this assumption of normality.\n\nBut what does \"normal\" actually mean? It assumes that the residuals are coming from a normal or Gaussian distribution. This distribution has a symmetrical bell-shape, where the centre is the mean, and half of the data are on either side of this.\n\nWe can see this in @fig-normdist. The mean of the normal distribution is indicated with the dashed blue line.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Normal distribution](glm-intro-glm_files/figure-html/fig-normdist-1.png){#fig-normdist width=672}\n:::\n:::\n\n\nWe can use the linear model we created previously, where we looked at the possible linear relationship between beak length and beak length. This is based on measurements of _G. fortis_ beaks in 1975.\n\nThe individual values of the residuals from this linear model are shown in @fig-normdist, panel B (in red), with the corresponding theoretical normal distribution in the background. We can see that the residuals follow this distribution reasonably well, which matches our conclusions from the Q-Q plot (see @fig-fortis1975_lm_dgplots).\n\nAll this means is that assuming that these residuals may come from a normal distribution isn't such a daft suggestion after all.\n\nNow look at this example:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Classification in beak shape](glm-intro-glm_files/figure-html/fig-beak_class-1.png){#fig-beak_class width=672}\n:::\n:::\n\n\nThe data in @fig-beak_class show the classification of beak shape for a collection of finches. They are either classed as `blunt` or `pointed`. Various (continuous) measurements were taken from each bird, with the beak length shown here.\n\nWe'll look into this example in more detail later. For now it's important to note that the response variable (`class`) is not continuous. In this case, it's a binary response (`blunt` or `pointed`). As a result, the assumptions for a regular linear model go out of the window. If we were foolish enough to fit a linear model to these data, then the residuals would look rather non-normal (@fig-beak_residuals).\n\n<!-- With generalised linear models we can actually still _model_ these data as a linear relationship between the predictor (beak length) and response variable (class). But we do this through a **link function** that is able to map this linear predictor to the non-linear relationship in the data. -->\n\n<!-- When we do this and then look at the residuals, we end up with residuals that are much more normally distributed (@fig-beak_residuals, B). -->\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Beak class model residuals](glm-intro-glm_files/figure-html/fig-beak_residuals-1.png){#fig-beak_residuals width=672}\n:::\n:::\n\n\nSo what do we do? Well, the normal distribution is not the only one there is. In @fig-dist_examples there are a few examples of distributions (including the normal one).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Different distributions](glm-intro-glm_files/figure-html/fig-dist_examples-1.png){#fig-dist_examples width=672}\n:::\n:::\n\n\nDifferent distributions are useful for different types of data. For example, a logistic distribution is particularly useful in the context of binary or proportional response data. The Poisson distribution is useful when we've got count data.\n\nIn order to understand how this can help us, we need to be aware of two more concepts: **linear predictors** and **link functions**.\n\n## Linear predictors\n\nThe nice thing about linear models is that the predictors are, well, linear. Straight lines make for easy interpretation of any potential relationship between predictor and response.\n\nAs mentioned before, predictors are in the form of a _linear combination_, where each predictor variable is multiplied by a coefficient and all the terms are added together:\n\n$$\n\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_3 + ...\n$$\n\nFortunately, this is no different for generalised linear models! We still have a linear combination but, as we'll see, if the relationship is not linear then we need an additional step before we can model the data.\n\nAt this point, we have two options at our disposal (well, there are more, but let's not muddy the waters too much).\n\n:::{.callout-important}\n\n1. Transform our data and use a normal linear model on the transformed data\n2. Use a generalised linear model (GLM)\n:::\n\nThe first option, transforming our data, seems like a useful option and can work. It keeps things familiar (we'd still use a standard linear model) and so all is well with the world. Up to the point of interpreting the data. If we, for example, log-transform our data, how do we interpret this? After all, the predictions of the linear model are directly related to the outcome or response variable. Transforming the data is usually done so that the residuals of the linear model resemble a more normal distribution. An unwanted side-effect of this is that this also changes the ratio scale properties of the measured variables [@stevens1946].\n\nThe second option would be to use a generalised linear model. Here we leave the data the same, and instead we _transform the linear predictor_. This enables us to map a _non-linear_ outcome (or response variable) to a _linear_ model. This transformation is done using a **link function**.\n\n## Link functions\n\nRight, now we've got that out of the way, let's illustrate this with an example. We'll look at some data that come from an analysis of gene flow across two finch species [@lamichhaney2020].\n\nThe data focus on two species, _Geospiza fortis_ and _G. scandens_. The measurements are split by a uniquely timed event: a particularly strong El Niño event in 1983. This event changed the vegetation and food supply of the finches, allowing F1 hybrids of the two species to survive, whereas before 1983 they could not. The measurements are classed as `early` (pre-1983) and `late` (1983 onwards).\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\nLet's first look at the different groups:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Beak classification pre- and post El Niño](glm-intro-glm_files/figure-html/fig-beak_classification-1.png){#fig-beak_classification width=672}\n:::\n:::\n\n\nWe can see that in the early time point (pre-1983) both species had relatively distinct beak shapes. Generally, _G. fortis_ had blunt beaks, whereas _G. scandens_ had pointed beaks.\n\nAfter the 1983 El Niño event, some of the F1 hybrids between the two species survived which, over time, started to show intermediate beak shapes. There's a lot more to this story, and we'll come back to it later. For now, let's say we were in a situation where we did not have the beak classification. but we did have the beak length measurements.\n\nCould we make some predictions about how likely a given measurement would be classified as blunt or pointed? Let's focus on just the early time points, where the effect is most pronounced. This is visualised in @fig-beak_classification_nospecies, A.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Beak classification without class information](glm-intro-glm_files/figure-html/fig-beak_classification_nospecies-1.png){#fig-beak_classification_nospecies width=672}\n:::\n:::\n\n\nWe could then try to model this with the knowledge we've got so far and perform a linear regression analysis, the results of which are in @fig-beak_classification_nospecies, B.\n\nThis is really bad practice. Why? Well, the linear model suggests that it is possible to have a higher than 100%, and lower-than-zero, probability that a beak would be pointed! That, makes no sense. So, we can't describe these data with some kind of linear relationship.\n\nInstead, we'll use a _logistic model_ to analyse these data. We'll cover the practicalities of how to do this in more detail in a later chapter, but for now it's sufficient to realise that one of the ways we could model these data could look like this:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Logistic model for beak classification](glm-intro-glm_files/figure-html/fig-beak_class_glm-1.png){#fig-beak_class_glm width=672}\n:::\n:::\n\n\nThis sigmoidal curve at least ensures that our predicted probabilities do not exceed the $[0, 1]$ range.\n\nNow, what happened behind the scenes is that the generalised linear model has taken the linear predictor and transformed it using the _logit_ function. This links the linear predictor to the non-linear _outcome_ (or response). Conversely, we can look at the fitted values of the model (before they get transformed). They look like this:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Fitted values for beak classification](glm-intro-glm_files/figure-html/fig-beak_class_glm_fitted-1.png){#fig-beak_class_glm_fitted width=672}\n:::\n:::\n\n\nAs we can see, the values predicted by the model are still on a linear scale!\n\nThe fitted model values are linear because the non-linear outcome (the relationship between beak length and beak classification) is linearised by the model, through the link function.\n\nIn this case we've used the _logit_ link function (more on this later). So the values we're seeing are on a logit scale. If we wanted to visualise the actual _probabilities_, we could do that as follows (also displaying the model predictions as a dashed line for clarity):\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Predicted probabilities for beak classification](glm-intro-glm_files/figure-html/fig-beak_class_glm_probs-1.png){#fig-beak_class_glm_probs width=672}\n:::\n:::\n\n\nFrom this we can see that the probability of having a pointed beak (which is considered a \"success\") is approaching 1 as the beak length gets longer.\n\nWhat about the residuals of the model? If all is well, then the residuals should, following the transformation, approach normality.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Residuals before and after link function](glm-intro-glm_files/figure-html/fig-beak_class_residuals-1.png){#fig-beak_class_residuals width=672}\n:::\n:::\n\n\nThis is displayed in @fig-beak_class_residuals. We can see the original residuals (based on the standard linear model) in @fig-beak_class_residuals, A. We've seen these before, with the corresponding hypothetical normal distribution in the background for comparison. The residuals look markedly different to a normal distribution!\n\nIn contrast, the residuals of the generalised linear model we created, via the link function, are in @fig-beak_class_residuals, B. They are not perfect, but clearly much improved!\n\n## Key points\n\n::: {.callout-note}\n- GLMs allow us to map a non-linear outcome to a linear model\n- The link function determines _how_ this occurs, transforming the linear predictor\n:::",
    "supporting": [
      "glm-intro-glm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}