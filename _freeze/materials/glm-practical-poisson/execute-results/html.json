{
  "hash": "a16ca644410f89e952514c95d5941686",
  "result": {
    "markdown": "---\ntitle: \"Poisson regression\"\n---\n\n::: {.cell}\n\n:::\n\n\n::: callout-note\n## Aims & objectives\n-   How do we analyse count data?\n-   Be able to perform a poisson regression on count data\n:::\n\n## Libraries and functions\n\n::: panel-tabset\n## tidyverse\n\n| Library      | Description                                                                            |\n|:-----------------------------------|:-----------------------------------|\n| `tidyverse`  | A collection of R packages designed for data science                                   |\n| `tidymodels` | A collection of packages for modelling and machine learning using tidyverse principles |\n| `poissonreg` | Enables the `parsnip` package to fit various types of Poisson regression models        |\n:::\n\n## Datasets\n\n::: panel-tabset\n## Islands\n\nThe example in this section uses the following data set:\n\n`data/islands.csv`\n\nThis is a data set comprising 35 observations of two variables (one dependent and one predictor). This records the number of species recorded on different small islands along with the area (km<sup>2</sup>) of the islands. The variables are `species` and `area`.\n\n## Seatbelts\n\nThe `seatbelts` data set is a multiple time-series data set that was commissioned by the Department of Transport in 1984 to measure differences in deaths before and after front seatbelt legislation was introduced on 31st January 1983. It provides monthly total numerical data on a number of incidents including those related to death and injury in Road Traffic Accidents (RTA's). The data set starts in January 1969 and observations run until December 1984.\n\nYou can find the file in `data/seatbelts.csv`\n:::\n\n## Visualise the data\n\nA good first step is always to explore your data prior to any further analysis.\n\n::: panel-tabset\n## tidyverse\n\nFirst, we load and inspect the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nislands <- read_csv(\"data/island.csv\")\n\nislands\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 35 × 2\n   species  area\n     <dbl> <dbl>\n 1     114  12.1\n 2     130  13.4\n 3     113  13.7\n 4     109  14.5\n 5     118  16.8\n 6     136  19.0\n 7     149  19.6\n 8     162  20.6\n 9     145  20.9\n10     148  21.0\n# … with 25 more rows\n```\n:::\n:::\n\n\nLooking at the data, we can see that there are two columns: `species`, which contains the number of species recorded on each island and `area`, which contains the surface area of the island in square kilometers.\n\nWe can plot the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nislands %>% \n  ggplot(aes(x = area, y = species)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](glm-practical-poisson_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n:::\n\nIt looks as though `area` may have an effect on the number of species that we observe on each island. We note that the response variable is count data and so we try to construct a Poisson regression.\n\n## Model building\n\nTo create a poisson regression we do the following:\n\n::: panel-tabset\n## tidyverse\n\nAgain, similar to what we've done for the logistic models, we will use the `parsnip` package from the `tidymodels` library. Yes, the workflow still seems a bit faffy, but it provides a common syntax for a whole range of modelling libraries. This means that the syntax will stay the same as you do different kind of model comparisons.\n\nIf you haven't loaded `tidymodels` yet, now is a really good time. We also need to load `poissonreg`, which adds extra functionality to `parsnip`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"tidymodels\")\nlibrary(tidymodels)\n# install.packages(\"poissonreg\")\nlibrary(poissonreg)\n```\n:::\n\n\nRemember that the workflow in `parsnip` is a bit different to what we're used to so far. Using `parsnip` we approach things in a more systematic manner. We specify a model in three steps:\n\n1.  **Specify the type of model based on its mathematical structure** (e.g., linear regression, logistic regression, poisson regression etc).\n\nFor example:\n\n-   `linear_reg()` for linear regression\n-   `logistic_reg()` for logistic regression\n-   `poisson_reg()` for poisson regression (we'll be using that here)\n\n2.  **When required, declare the mode of the model.** The mode reflects the type of prediction outcome. For numeric outcomes, the mode is *regression*; for qualitative outcomes, it is *classification.* If a model can only create one type of model, such as poisson regression, the mode is already set to, in this case, `mode = \"regression\"`.\n\n3.  **Specify the engine for fitting the model.** This usually is the software package or library that should be used.\n\nFor example,\n\n-   `\"lm\"` for linear models\n-   `\"glm\"` for generalised linear models\n-   `\"stan\"` for Bayesian inference\n\nYou can find out which engines can be used with the `show_engines()` function. The command `show_engines(\"poisson_reg\")` will give you the available engines for the `poisson_reg()` function.\n\nSo, we can create the model as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nisl_mod <- poisson_reg() %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"glm\")\n```\n:::\n\n\nNote that we are not actually specifying any of the variables just yet! All we've done is tell R what kind of model we're planning to use. If we want to see how `parsnip` converts this code to the package syntax, we can check this with `translate()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nisl_mod %>% translate()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPoisson Regression Model Specification (regression)\n\nComputational engine: glm \n\nModel fit template:\nstats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n    family = stats::poisson)\n```\n:::\n:::\n\n\nThis shows that we have a poisson regression model, where the outcome is going to be a regression. The model fit template tells us that we'll be using the `glm()` function from the `stats` package, which can take a `formula`, `data`, `weights` and `family` argument. The `family` argument is already set to poisson.\n\nThe model fit template tells us that we'll be using the `glm()` function from the `stats` package (`stats::glm`). This function has several arguments:\n\n1.  a `formula`, which we'll specify later\n2.  `data`, which we'll provide in a bit\n3.  `weights`, if we want to add prior weights to our variable - we don't have to concern ourselves with this - and\n4.  a `family` argument, which is already set to `poisson`\n\n::: callout-important\n## The `family` argument\n\nThe `family` argument gives us a description of the error distribution and link function that will be used in the model. For the `islands` data set we are looking at count outcome - which we can model using a *poisson* regression model.\n\nIf we'd want to specify it manually, then we'd use\n\n`set_engine(\"glm\", family = stats::poisson(link = \"log\"))`\n\nwhich sets the family to poisson, using a log link function.\n:::\n\nNow we've specified what kind of model we're planning to use, we can fit our data to it, using the `fit()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nisl_fit <- isl_mod %>% \n  fit(species ~ area,\n      data = islands)\n```\n:::\n\n\nWe can look at the output directly, but I prefer to tidy the data up using the `tidy()` function from `broom` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nisl_fit %>% tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)   4.24     0.0413      103.  0        \n2 area          0.0356   0.00125      28.6 2.73e-179\n```\n:::\n:::\n\n\nThe output is strikingly similar to the binomial models (who'd have guessed, eh?) and the main numbers to extract from the output are the two numbers in the `estimate` column.\n:::\n\nThese are the coefficients of the Poisson model equation and need to be placed in the following formula in order to estimate the expected number of species as a function of island size:\n\n$$ E(species) = \\exp(4.24 + 0.036 \\times area) $$\n\nInterpreting this requires a bit of thought (not much, but a bit).\n\nThe intercept coefficient ($\\beta_0$), 4.24, is related to the number of species we would expect on an island of zero area (this is statistics, not real life. You'd do well to remember that before you worry too much about what that even means). But in order to turn this number into something meaningful we have to exponentiate it. Since $\\exp(4.24) \\approx 70$, we can say that the baseline number of species the model expects on any island is 70. This isn't actually the interesting bit though.\n\nThe coefficient of `area` ($\\beta_1$) is the fun bit. For starters we can see that it is a positive number which does mean that increasing area leads to increasing numbers of species. Good so far - since this matches what we saw when we plotted our data. But what does the value 0.036 actually mean?\n\nWell, if we exponentiate it too we get $\\exp(0.036) \\approx 1.04$. This means that for every increase in area of 1 km<sup>2</sup> (the original units of the `area` variable) the number of species on the island is multiplied by 1.04. So, an island of area 1 km<sup>2</sup> is predicted to have $1.04 \\times 70 \\approx 72$ species.\n\nSo, in order to interpret Poisson coefficients, you have to exponentiate them.\n\n## Model predictions\n\nNow that we can interpret the Poisson coefficients, it would be good to see if using a poisson regression to describe these data is actually a good idea.\n\nVisualisation is always useful, so in order to get an idea of how our data fits a Poisson regression, we'll plot the Poisson regression curve. Next, we overlay our original data.\n\n::: panel-tabset\n## tidyverse\n\nFirst, we create a table that contains data for the curve, starting for an `area` with value 1 to 50, in steps of 1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- tibble(area = seq(1, 50, 1))\n```\n:::\n\n\nNext, we feed our model these data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncurve <- isl_fit %>% augment(new_data = model)\n```\n:::\n\n\nThis gives the predicted number of `species` for each given value of `area`. If we have a closer look at these data we can see that, for example, for an `area` with a surface area of 4 km<sup>2</sup> the predicted number of species is around 80. Nice.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(curve)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 2\n   area .pred\n  <dbl> <dbl>\n1     1  72.0\n2     2  74.6\n3     3  77.3\n4     4  80.1\n5     5  83.0\n6     6  86.0\n```\n:::\n:::\n\n\nUsing these data, we can now plot all the *predicted* number of species and overlay our original *measured* data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(curve, aes(area, .pred)) +\n  geom_line(colour = \"red\") +\n  geom_point(data = islands, aes(area, species))\n```\n\n::: {.cell-output-display}\n![](glm-practical-poisson_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n:::\n\nThat looks like a pretty decent fit, really. But of course we want to have a (slightly) less hand-wavy conclusion than that.\n\n## Goodness-of-fit\n\nWe can use the model's residual deviance to assess how much the predicted values differ from the observed. This gives us an idea of how well-specified the model is. When a model is \"true\", *i.e.* the model makes pretty accurate predictions, then we expect the residual deviance to be distributed as a $\\chi^2$ random variable with degrees of freedom equal to the model's residual degrees of freedom.\n\n::: panel-tabset\n## tidyverse\n\nWe can get these parameters as follows and we'll store them in a new object, so we can extract them in a bit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nisl_fit %>% glance()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n1          857.      34  -139.  283.  286.     30.4          33    35\n```\n:::\n\n```{.r .cell-code}\nisl_parameters <- isl_fit %>% glance()\n```\n:::\n\n\nThe values we are interested in are in the `deviance` and `df.residual` columns, respectively.\n\nNext, we use the `pchisq()` function to calculate the correct probability.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npchisq(isl_parameters$deviance,\n       isl_parameters$df.residual,\n       lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.595347\n```\n:::\n:::\n\n\nThis gives us a value of around 0.60. This suggests that this model is actually a pretty good one (if it wasn't then the value would be close to zero) and that the data are pretty well supported by the model.\n\n::: callout-important\nThe `pchisq()` function gives the lower tail probability that $\\chi^2 \\le x$ by default. We're actually interested in the probability that $\\chi^2 \\ge x$. These two probabilities must sum to one, so we get the upper tail probability by setting the argument `lower.tail = FALSE`. An alternative way would be to use the default, but do `1 - pchisq()`.\n:::\n\nFor Poisson models this has an extra interpretation. This can be used to assess whether we have significant overdispersion in our data. For a Poisson model to be appropriate we need that the variance of the data to be exactly the same as the mean of the data. If there is overdispersion then the data would spread out more for higher predicted values of species than for lower ones. Our visualisation shows that this isn't really happening. The spread is unlikely to be perfectly homogeneous, but we don't want the data to spread out too much.\n\nThe easy way to check this is to look at the ratio of the residual deviance to the residual degrees of freedom (in this case 0.922). For a Poisson model to be valid, this ratio should be about 1. If the ratio is significantly bigger than 1 then we say that we have over-dispersion in the model and we wouldn't be able to trust any of the significance testing using a Poisson regression.\n:::\n\n## Confidence intervals\n\nWe can also assess how reliable our model is by looking at the confidence intervals of the estimated parameters.\n\n::: panel-tabset\n## tidyverse\n\nWe extracted the parameters of the model by using\n\n\n::: {.cell}\n\n```{.r .cell-code}\nisl_fit %>% tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)   4.24     0.0413      103.  0        \n2 area          0.0356   0.00125      28.6 2.73e-179\n```\n:::\n:::\n\n\nAlthough we focussed on the `estimate` column, we can see that the associated standard errors for each estimate is also given in the `std.error` column. We can use these values to calculate the 95% confidence intervals.\n\nWe can either do this by hand through multiplying the standard errors by 1.96. We can then subtract from (giving the lower confidence estimate) or add to (giving the higher confidence estimate) the estimated parameter. This gives a pretty decent approximation.\n\nBut then again, life is short, so we can just use the additional argument that is available for the `tidy()` function. You can look at what columns are returned, but I'm selecting the relevant ones here:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nisl_fit %>% tidy(conf.int = TRUE,        # default is FALSE\n                 conf.level = 0.95) %>%  # is the default\n  select(term, estimate, conf.low, conf.high)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  term        estimate conf.low conf.high\n  <chr>          <dbl>    <dbl>     <dbl>\n1 (Intercept)   4.24     4.16      4.32  \n2 area          0.0356   0.0332    0.0381\n```\n:::\n:::\n\n\nWhat we're interested in here is the confidence intervals for the `area` parameter. Before we delve into that, I'm also going to calculate the exponent for these confidence intervals. We can do this using the `exp()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nisl_fit %>% tidy(conf.int = TRUE,        # default is FALSE\n                 conf.level = 0.95) %>%  # is the default\n  select(term, estimate, conf.low, conf.high) %>% \n  mutate(conf.low_exp = exp(conf.low),\n         conf.high_exp = exp(conf.high))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  term        estimate conf.low conf.high conf.low_exp conf.high_exp\n  <chr>          <dbl>    <dbl>     <dbl>        <dbl>         <dbl>\n1 (Intercept)   4.24     4.16      4.32          64.1          75.3 \n2 area          0.0356   0.0332    0.0381         1.03          1.04\n```\n:::\n:::\n\n\nThese values are a bit familiar, since we've previously determined based on the `area` coefficient that for each increase in square kilometer, the number of species increases by approximately 1.04.\n\nWhat these values tell us is that we can be 95% certain that for every increase in square kilometer of island area size, the number of species increases by a factor of somewhere between 1.034 and 1.039.\n\n::: callout-note\nIf there was no association between `area` and `species`, then the $\\beta_1$ coefficient would be zero. That would mean that the exponent would be ${e}^{\\beta_1}=1$. The interval that we calculated for ${e}^{\\beta_1}$ lies between 1.034 and 1.039 and therefore does not include 1, so the model with `area` is preferred over the model without `area`.\n\nEquivalently, the interval for $\\beta_1$ (0.033 - 0.038) does not include 0, again showing the significance of `area` as a predictor of `species`.\n:::\n:::\n\n## Exercise: Seatbelts\n\nI'd like you to do the following:\n\n1.  Load the data\n2.  Visualise the data and create a poisson regression model\n3.  Plot the regression model on top of the data\n4.  Assess if the model is a decent predictor for the number of fatalities\n\n::: {.callout-caution collapse=\"true\"}\n## Answer\n\n### Load the data\n\nFirst, we load the data.\n\n::: panel-tabset\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseatbelts <- read_csv(\"data/seatbelts.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 192 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): month\ndbl (9): drivers_killed, drivers, front, rear, kms, petrol_price, van_killed...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n:::\n\n### Visualise the data\n\nThe data tracks the number of drivers killed in road traffic accidents, before and after the seatbelt law was introduced. The information on whether the law was in place is encoded in the `law` column as `0` (law not in place) or `1` (law in place).\n\nThere are many more observations when the law was *not* in place, so we need to keep this in mind when we're interpreting the data.\n\nFirst we have a look at the data comparing no law vs law:\n\n::: panel-tabset\n## tidyverse\n\nWe have to convert the `law` column to a factor, otherwise R will see it as numerical.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseatbelts %>% \n  ggplot(aes(as_factor(law), drivers_killed)) +\n   geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](glm-practical-poisson_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nThe data are recorded by month and year, so we can also display the number of drivers killed by year:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseatbelts %>% \n  ggplot(aes(year, drivers_killed)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](glm-practical-poisson_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n:::\n\nThe data look a bit weird. There is quite some variation within years (keeping in mind that the data are aggregated monthly). The data also seems to wave around a bit... with some vague peaks (e.g. 1972 - 1973) and some troughs (e.g. around 1976).\n\nSo my initial thought is that these data are going to be a bit tricky to interpret. But that's OK.\n\n### Model building\n\nWe're dealing with count data, so we're going to use a poisson regression.\n\n::: panel-tabset\n## tidyverse\n\nAs before, we first define the model type.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstb_mod <- poisson_reg() %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"glm\")\n```\n:::\n\n\nAnd check that everything is in order.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstb_mod %>% translate()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPoisson Regression Model Specification (regression)\n\nComputational engine: glm \n\nModel fit template:\nstats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n    family = stats::poisson)\n```\n:::\n:::\n\n\nNext, we fit our data to the model we just specified:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstb_fit <- stb_mod %>% \n  fit(drivers_killed ~ year,\n      data = seatbelts)\n```\n:::\n\n\nAnd we can extract the estimated coefficients from these fitted data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstb_fit %>% tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  37.2      2.80         13.3 2.62e-40\n2 year         -0.0164   0.00142     -11.6 5.88e-31\n```\n:::\n:::\n\n:::\n\n### Visualise the model\n\nTo see if the model is actually a decent prediction for our data, we can plot it.\n\n::: panel-tabset\n## tidyverse\n\nTo do this, we create modelled values for our predictor variable `year`. Because we have monthly data, we create a sequence of \"years\" in 1/12th intervals - one for each month.\n\nNext, we ask the model to predict the number of drivers killed based on these values.\n\nLastly, we can plot those predicted values against the observed values in our data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create the sequence of values that are used\n# in predicting number of deaths\nmodel <- tibble(year = seq(1969, 1984, (1/12)))\n\n# fit these data to the model\nstb_curve <- stb_fit %>% augment(new_data = model)\n\n# plot the predicted values\n# and overlay the observed values\nggplot(seatbelts, aes(year, drivers_killed)) +\n  geom_point() +\n  geom_point(data = stb_curve, aes(x = year, y = .pred),\n             colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](glm-practical-poisson_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n:::\n\nThat does not look like a very good fit, but then again the data look rather messy as well.\n\n### Goodness-of-fit\n\nLet's check the goodness-of-fit.\n\n::: panel-tabset\n## tidyverse\n\nFirst we store the parameter estimates in an object. Then we use the `pchisq()` function to calculate the probability that the residual deviance is actually distributed as a $\\chi^2$ random variable with degrees of freedom equal to the model's residual degrees of freedom.\n\nYes, you can read that sentence three times and still wonder what that really means. Suffice to say is that the outcome gives us a measure of how well-specified the model is.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstb_parameter <- stb_fit %>% glance()\n\nstb_parameter\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n1          984.     191 -1062. 2127. 2134.     850.         190   192\n```\n:::\n\n```{.r .cell-code}\npchisq(stb_parameter$deviance,\n       stb_parameter$df.residual,\n       lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3.12987e-84\n```\n:::\n:::\n\n:::\n\nWell, that's a bit of a blow. The probability value is extremely low, suggesting that the model is not very well-specified. Which kind of matches what we already saw in the plot. It might still be better than the null model (\"the data can be modelled as the average across all the observations\"), but we seem to be missing some parameters here.\n\n### Confidence intervals\n\nSimilar to the `islands` example, we can also calculate the confidence intervals associated with our estimated parameters.\n\n::: panel-tabset\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstb_fit %>% tidy(conf.int = TRUE,        # default is FALSE\n                 conf.level = 0.95) %>%  # is the default\n  select(term, estimate, conf.low, conf.high) %>% \n  mutate(conf.low_exp = exp(conf.low),\n         conf.high_exp = exp(conf.high))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  term        estimate conf.low conf.high conf.low_exp conf.high_exp\n  <chr>          <dbl>    <dbl>     <dbl>        <dbl>         <dbl>\n1 (Intercept)  37.2     31.7      42.7        5.78e+13      3.34e+18\n2 year         -0.0164  -0.0191   -0.0136     9.81e- 1      9.86e- 1\n```\n:::\n:::\n\n\nWe're interested in the confidence interval for the `year` variable. Remember that if there is no association at all between `year` and `drivers_killed` then the parameter $e^{\\beta_1} = 1$.\n\nIn our case the interval we calculated for $e^{\\beta_1}$ lies between 0.981 and 0.986. This does not include 1, so it seems that the model that takes `year` into account is still preferred over a model that doesn't.\n:::\n:::\n\n## Key points\n\n::: callout-note\n-   Poisson regression is useful when dealing with count data\n:::\n",
    "supporting": [
      "glm-practical-poisson_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}