{
  "hash": "156677463a65ba88a08cd01df36c43df",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Overdispersed count data\"\nlightbox: true\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n::: {.callout-tip}\n## Learning outcomes\n\n-   Understand what dispersion is and why it's important\n-   Be able to diagnose or recognise overdispersion in count data\n-   Fit a negative binomial regression model to overdispersed count data\n-   Know the difference between Poisson and negative binomial regression\n-   Assess whether assumptions are met and evaluate fit of a negative binomial model\n:::\n\n## Context\nIn the previous chapter we looked at how to analyse count data. We used a Poisson regression to do this, which makes assumptions about the dispersion parameter. If everything is as expected (the mean and variance are they same) it's 1. But, data are rarely that compliant so we need to be able to deal with situations where this is not the case. Here, we look at the situation where we have overdispersion.\n\n## Libraries and functions\n\n::: {.callout-note collapse=\"true\"}\n## Click to expand\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n### Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(performance)\nlibrary(tidyverse)\nlibrary(broom)\n```\n:::\n\n\n## Python\n\n### Libraries\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# A maths library\nimport math\nimport pandas as pd\nfrom plotnine import *\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.stats import *\nimport numpy as np\nfrom statsmodels.discrete.discrete_model import NegativeBinomial\n```\n:::\n\n:::\n:::\n\n## Removing dispersion assumptions\n\nWhen we analysed the count data in the previous chapter, we used a Poisson regression. This makes the assumption that the dispersion parameter $\\approx 1$ (for a refresher on dispersion, see [Section @sec-mat_dispersion]).\n\nHere we look at a situation where that assumption is violated and the dispersion parameter is much larger than 1. For this we turn to negative binomial models. Instead of making an assumption about the dispersion parameter, they **estimate** it as part of the model fitting.\n\n## Parasites dataset\n\nWe'll explore this with the `parasites` dataset. \n\nThese data are about parasites found on the gills of freshwater fish.\n\nThe ecologists who conducted the research observed a total of 64 fish, which varied by:\n\n-   which `lake` they were found in\n-   the `fish_length` (cm)\n\nThey were interested in how these factors influenced the `parasite_count` of small parasites found on each fish.\n\n## Load and visualise the data\n\nFirst we load the data, then we visualise it.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparasites <- read_csv(\"data/parasites.csv\")\n\nhead(parasites)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  parasite_count lake  fish_length\n           <dbl> <chr>       <dbl>\n1             46 C            21.1\n2            138 C            26.4\n3             23 C            18.9\n4             35 B            27.2\n5            118 C            29  \n6             43 B            24.2\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(parasites, aes(y = parasite_count, x = fish_length, colour = lake)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(parasites, aes(y = parasite_count, x = lake, colour = fish_length)) +\n  geom_violin() +\n  geom_jitter(width = 0.2)\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nparasites = pd.read_csv(\"data/parasites.csv\")\n\nparasites.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   parasite_count lake  fish_length\n0              46    C         21.1\n1             138    C         26.4\n2              23    C         18.9\n3              35    B         27.2\n4             118    C         29.0\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(parasites, aes(x = \"fish_length\", y = \"parasite_count\",\n                           colour = \"lake\")) +\n       geom_point())\n\np.show()\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-8-1.png){width=614}\n:::\n\n```{.python .cell-code}\np = (ggplot(parasites, aes(x = \"lake\", y = \"parasite_count\",\n                       colour = \"fish_length\")) +\n   geom_violin() +\n   geom_jitter(width = 0.2))\n\np.show()\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-8-2.png){width=614}\n:::\n:::\n\n:::\n\nWe get a reasonably clear picture here; it seems that `lake C` might have a higher number of parasites overall, and that across all three lakes, bigger fish have more parasites too.\n\n## Constructing a Poisson model\n\nGiven that the response variable, `parasite_count`, is a count variable, let's try to construct a Poisson regression. \n\nWe'll construct the full model, with an interaction.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_para <- glm(parasite_count ~ lake * fish_length,\n                data = parasites, family = \"poisson\")\n```\n:::\n\n\nand we look at the model summary:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(glm_para)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = parasite_count ~ lake * fish_length, family = \"poisson\", \n    data = parasites)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        1.656e+00  1.763e-01   9.391   <2e-16 ***\nlakeB             -7.854e-01  2.804e-01  -2.801   0.0051 ** \nlakeC              3.527e-01  2.261e-01   1.560   0.1188    \nfish_length        9.127e-02  6.643e-03  13.738   <2e-16 ***\nlakeB:fish_length  1.523e-02  1.031e-02   1.477   0.1398    \nlakeC:fish_length -5.079e-05  8.389e-03  -0.006   0.9952    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2073.8  on 63  degrees of freedom\nResidual deviance: 1056.5  on 58  degrees of freedom\nAIC: 1429.2\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel = smf.glm(formula = \"parasite_count ~ lake * fish_length\",\n                family = sm.families.Poisson(),\n                data = parasites)\n\nglm_para = model.fit()\n```\n:::\n\n\nLet's look at the model output:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(glm_para.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:         parasite_count   No. Observations:                   64\nModel:                            GLM   Df Residuals:                       58\nModel Family:                 Poisson   Df Model:                            5\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -708.61\nDate:                Tue, 22 Jul 2025   Deviance:                       1056.5\nTime:                        17:04:34   Pearson chi2:                 1.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):              1.000\nCovariance Type:            nonrobust                                         \n=========================================================================================\n                            coef    std err          z      P>|z|      [0.025      0.975]\n-----------------------------------------------------------------------------------------\nIntercept                 1.6556      0.176      9.391      0.000       1.310       2.001\nlake[T.B]                -0.7854      0.280     -2.801      0.005      -1.335      -0.236\nlake[T.C]                 0.3527      0.226      1.560      0.119      -0.090       0.796\nfish_length               0.0913      0.007     13.738      0.000       0.078       0.104\nlake[T.B]:fish_length     0.0152      0.010      1.477      0.140      -0.005       0.035\nlake[T.C]:fish_length -5.079e-05      0.008     -0.006      0.995      -0.016       0.016\n=========================================================================================\n```\n\n\n:::\n:::\n\n:::\n\n### Checking dispersion\n\nBefore we launch into any significance testing, we're going to check one of the assumptions: that the dispersion parameter = 1 (you might've guessed where this is going...)\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_overdispersion(glm_para)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Overdispersion test\n\n       dispersion ratio =   18.378\n  Pearson's Chi-Squared = 1065.905\n                p-value =  < 0.001\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nOverdispersion detected.\n```\n\n\n:::\n:::\n\n\n## Python\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(glm_para.deviance/glm_para.df_resid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n18.215417572845308\n```\n\n\n:::\n\n```{.python .cell-code}\npvalue = chi2.sf(glm_para.deviance, glm_para.df_resid)\nprint(pvalue)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2.3125874815114225e-183\n```\n\n\n:::\n:::\n\n:::\n\nOh no - there is *definitely* overdispersion here.\n\nWe won’t bother looking at the analysis of deviance table or asking whether the model is better than the null model. The Poisson regression we've fitted here is not right, and we need to fit a different type of model.\n\nThe main alternative to a Poisson model, used for overdispersed count data, is something called a negative binomial model. \n\n## Negative binomial model\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nTo specify a negative binomial model, we use the `glm.nb` function from the `MASS` package.\n\nThe syntax is the same as `glm`, except we don't need to specify a `family` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_para <- glm.nb(parasite_count ~ lake * fish_length, parasites)\n\nsummary(nb_para)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = parasite_count ~ lake * fish_length, data = parasites, \n    init.theta = 3.37859216, link = log)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(>|z|)   \n(Intercept)        1.943370   0.739434   2.628  0.00858 **\nlakeB             -0.784885   1.094625  -0.717  0.47335   \nlakeC              0.212060   1.006021   0.211  0.83305   \nfish_length        0.079939   0.029485   2.711  0.00671 **\nlakeB:fish_length  0.015428   0.043380   0.356  0.72210   \nlakeC:fish_length  0.005719   0.039542   0.145  0.88501   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(3.3786) family taken to be 1)\n\n    Null deviance: 118.202  on 63  degrees of freedom\nResidual deviance:  67.288  on 58  degrees of freedom\nAIC: 615.99\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  3.379 \n          Std. Err.:  0.623 \n\n 2 x log-likelihood:  -601.991 \n```\n\n\n:::\n:::\n\n\nThis output is very similar to the other GLM outputs that we’ve seen but with some additional information at the bottom regarding the dispersion parameter that the negative binomial model has used, which in R is called theta ($\\theta$), 3.379. \n\nThis number is estimated from the data. This is what makes negative binomial regression different from Poisson regression.\n\n## Python\n\nWe can continue to use `statsmodels`, specifically the `NegativeBinomial` function.\n\nThe syntax for getting this to work is a little different, and takes several steps.\n\nFirst, we identify our response variable:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nY = parasites['parasite_count']\n```\n:::\n\n\nNow, we need to set up our set of predictors. The function we're using requires us to provide a matrix where each row is a unique observation (fish, in this case) and each column is a predictor.\n\nBecause we want to include the `lake:fish_length` interaction, we actually need to manually generate those columns ourselves, like this:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# 1. Create dummy variables for 'lake' (switch to True/False values)\nlake_dummies = pd.get_dummies(parasites['lake'], drop_first=True)\n\n# 2. Create interaction terms manually: lake_dummies * fish_length\ninteractions = lake_dummies.multiply(parasites['fish_length'], axis=0)\ninteractions.columns = [f'{col}:fish_length' for col in interactions.columns]\n\n# 3. Combine all predictors: fish_length, lake dummies, interactions\nX = pd.concat([parasites['fish_length'], lake_dummies, interactions], axis=1)\n\n# 4. Add a constant/intercept (required), and make sure that we're using floats\nX = sm.add_constant(X).astype(float)\n```\n:::\n\n\nNow, we can fit our model and look at the summary:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom statsmodels.discrete.discrete_model import NegativeBinomial\n\n# Specify the model (Y, X)\nmodel = NegativeBinomial(Y, X)\n\nnb_para = model.fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOptimization terminated successfully.\n         Current function value: 4.703057\n         Iterations: 32\n         Function evaluations: 39\n         Gradient evaluations: 39\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(nb_para.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     NegativeBinomial Regression Results                      \n==============================================================================\nDep. Variable:         parasite_count   No. Observations:                   64\nModel:               NegativeBinomial   Df Residuals:                       58\nMethod:                           MLE   Df Model:                            5\nDate:                Tue, 22 Jul 2025   Pseudo R-squ.:                 0.05947\nTime:                        17:04:34   Log-Likelihood:                -301.00\nconverged:                       True   LL-Null:                       -320.03\nCovariance Type:            nonrobust   LLR p-value:                 3.658e-07\n=================================================================================\n                    coef    std err          z      P>|z|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst             1.9434      0.689      2.819      0.005       0.592       3.294\nfish_length       0.0799      0.027      2.915      0.004       0.026       0.134\nB                -0.7849      1.026     -0.765      0.444      -2.796       1.226\nC                 0.2121      0.961      0.221      0.825      -1.671       2.095\nB:fish_length     0.0154      0.041      0.380      0.704      -0.064       0.095\nC:fish_length     0.0057      0.038      0.152      0.879      -0.068       0.080\nalpha             0.2960      0.055      5.424      0.000       0.189       0.403\n=================================================================================\n```\n\n\n:::\n:::\n\n\nIn particular, we might like to know what the dispersion parameter is.\n\nBy default, `NegativeBinomial` from `statsmodels` provides something called alpha ($\\alpha$), which is not the same as the significance threshold. To convert this into the dispersion parameter you're using to seeing (sometimes referred to as theta, $\\theta$), you need $\\frac{1}{\\alpha}$.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(1/nb_para.params['alpha'])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n3.378591992548569\n```\n\n\n:::\n:::\n\n:::\n\n### Extract equation\n\nIf we wanted to express our model as a formal equation, we need to extract the coefficients:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefficients(nb_para)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      (Intercept)             lakeB             lakeC       fish_length \n      1.943370195      -0.784885086       0.212060149       0.079939234 \nlakeB:fish_length lakeC:fish_length \n      0.015428470       0.005718571 \n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(nb_para.params)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nconst            1.943370\nfish_length      0.079939\nB               -0.784885\nC                0.212060\nB:fish_length    0.015428\nC:fish_length    0.005719\nalpha            0.295981\ndtype: float64\n```\n\n\n:::\n:::\n\n:::\n\n\n::: {.cell}\n\n:::\n\n\n\nThese are the coefficients of the negative binomial model equation and need to be placed in the following formula in order to estimate the expected number of species as a function of the other variables:\n\n$$\n\\begin{split}\nE(species) = \\exp(1.94 + \\begin{pmatrix} 0 \\\\ -0.78 \\\\ 0.212 \\end{pmatrix} \\begin{pmatrix} A \\\\ B \\\\ C \\end{pmatrix} + 0.08 \\times fishlength + \\begin{pmatrix} 0 \\\\ 0.0154 \\\\ 0.0057 \\end{pmatrix} \\begin{pmatrix} A \\\\ B \\\\ C \\end{pmatrix} \\times fishlength)\n\\end{split}\n$$\n\n### Comparing Poisson and negative binomial\n\nA Poisson regression and negative binomial regression are very similar to each other. They use the same link function - the log link function. There is however a key difference.\n\n::: {.callout-important}\n#### Difference Poisson and negative binomial\nIn a Poisson regression the dispersion parameter $\\lambda$ = 1. In a negative binomial regression it is estimated from the data.\n:::\n\nThis means they will both have equations in the same form, as we just showed above. It also means that they can produce some quite similar-looking models.\n\nLet's visualise and compare them.\n\nFirst, let's plot the Poisson model:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(parasites, aes(x = fish_length, y = parasite_count, colour = lake)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", se = FALSE, fullrange = TRUE, \n              method.args = list(family = \"poisson\"))\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n## Python\n\nTo do this, we need to produce a set of predictions, which we can then plot.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Get unique lake values from your dataset\nlake_levels = parasites['lake'].unique()\n\n# Create prediction grid for each lake\nnew_data = pd.concat([\n    pd.DataFrame({\n        'fish_length': np.linspace(10, 40, 100),\n        'lake': lake\n    }) for lake in lake_levels\n])\n\n# Predict\nnew_data['pred'] = glm_para.predict(new_data)\n\nnew_data.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   fish_length lake       pred\n0    10.000000    C  18.549643\n1    10.303030    C  19.069529\n2    10.606061    C  19.603986\n3    10.909091    C  20.153422\n4    11.212121    C  20.718257\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(parasites, aes(x = \"fish_length\",\n                           y = \"parasite_count\",\n                           colour = \"lake\")) +\n   geom_point() +\n   geom_line(new_data, aes(x = \"fish_length\", y = \"pred\",\n                           colour = \"lake\"), size = 1))\n\np.show()\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-24-1.png){width=614}\n:::\n:::\n\n:::\n\nNow, let's plot the negative binomial model:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nAll we have to do is switch the `method` for `geom_smooth` over to `glm.nb`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(parasites, aes(y = parasite_count, x = fish_length, colour = lake)) +\n  geom_point() +\n  geom_smooth(method = \"glm.nb\", se = FALSE, fullrange = TRUE)\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-25-3.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Get unique lake values from your dataset\nlake_levels = parasites['lake'].unique()\n\n# Create prediction grid for each lake\nnew_data_nb = pd.concat([\n    pd.DataFrame({\n        'fish_length': np.linspace(10, 40, 100),\n        'lake': lake\n    }) for lake in lake_levels\n])\n\n# Repeat the transformations we used when fitting the model\nlake_dummies = pd.get_dummies(new_data['lake'], drop_first=True)\ninteractions = lake_dummies.multiply(new_data_nb['fish_length'], axis=0)\ninteractions.columns = [f'{col}:fish_length' for col in interactions.columns]\nX_new = pd.concat([new_data_nb['fish_length'], lake_dummies, interactions], axis=1)\nX_new = sm.add_constant(X_new).astype(float)\n\n# Now we can safely predict:\nnew_data_nb['pred'] = nb_para.predict(X_new)\n\nnew_data_nb.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   fish_length lake       pred\n0    10.000000    C  20.328185\n1    10.303030    C  20.862750\n2    10.606061    C  21.411372\n3    10.909091    C  21.974421\n4    11.212121    C  22.552276\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(parasites, aes(x = \"fish_length\",\n                           y = \"parasite_count\",\n                           colour = \"lake\")) +\n   geom_point() +\n   geom_line(new_data_nb, aes(x = \"fish_length\", y = \"pred\",\n                              colour = \"lake\"), size = 1))\n\np.show()\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-27-1.png){width=614}\n:::\n:::\n\n:::\n\nIt's subtle - the two sets of curves look quite similar - but they're not quite the same.\n\nLooking at them side-by-side may help:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-28-3.png){width=672}\n:::\n:::\n\n\n\n### Checking assumptions & model quality\n\nThese steps are performed in precisely the same way we would do for a Poisson regression.\n\nRemember, the things we checked for in a Poisson regression were:\n\n-   Response distribution\n-   Correct link function\n-   Independence\n-   Influential points\n-   Collinearity\n-   Dispersion\n\nFor free, I'll just tell you now that the first three assumptions are met.\n\nPlus, we don't have to worry about dispersion with a negative binomial model. \n\nSo, all we really need to pay attention to is whether there are any influential points to worry about, or any collinearity.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nOnce again, the `performance` package comes in handy for assessing all of these.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(nb_para, check = c('pp_check',\n                               'vif',\n                               'outliers'))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `negbin`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncheck_outliers(nb_para, threshold = list('cook'=0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.5).\n- For variable: (Whole model)\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_collinearity(nb_para)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nModel has interaction terms. VIFs might be inflated.\n  Try to center the variables used for the interaction, or check\n  multicollinearity among predictors of a model without interaction terms.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Check for Multicollinearity\n\nLow Correlation\n\n        Term  VIF        VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n fish_length 3.13 [  2.26,    4.61]     1.77      0.32     [0.22, 0.44]\n\nHigh Correlation\n\n             Term     VIF        VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n             lake 1321.85 [863.04, 2024.86]    36.36  7.57e-04     [0.00, 0.00]\n lake:fish_length 1430.57 [934.01, 2191.42]    37.82  6.99e-04     [0.00, 0.00]\n```\n\n\n:::\n:::\n\n\n## Python\n\nWe check these things similarly to how we've done it previously.\n\nFor influential points, we're actually going to refit our model via `smf.glm` (which will give us access to `get_influence`). However, we'll use the `alpha` value that was estimated from the model we fitted with `NegativeBinomial`, rather than making any assumptions about its value.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nalpha_est = nb_para.params['alpha']\n\nmodel = smf.glm(formula='parasite_count ~ lake * fish_length',\n                data=parasites,\n                family=sm.families.NegativeBinomial(alpha = alpha_est))\n\nglm_nb_para = model.fit()\n```\n:::\n\n\nNow we can check influential points:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ninfluence = glm_nb_para.get_influence()\n\ncooks = influence.cooks_distance[0]\n\ninfluential_points = np.where(cooks > 0.5)[0] # Set appropriate threshold here\n\nprint(\"Influential points:\", influential_points)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluential points: [19 26]\n```\n\n\n:::\n:::\n\n\nThere seem to be a couple of points with a higher Cook's distance. If you investigate a bit further, they both still have a Cook's distance of <1, and neither of them cause dramatic changes to the model fit if removed.\n\nThe method that we're using here to assess influence is quite sensitive, so a threshold of 1 might be more appropriate.\n\nCollinearity/variance inflation factors:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom patsy import dmatrix\n\n# Drop the response variable\nX = parasites.drop(columns='parasite_count')\n\n# Create design matrix based on model formula\nX = dmatrix(\"lake * fish_length\", data=parasites, return_type='dataframe')\n\n# Calculate VIF for each feature\nvif_data = pd.DataFrame()\nvif_data['feature'] = X.columns\nvif_data['VIF'] = [variance_inflation_factor(X.values, i)\n                   for i in range(X.shape[1])]\n\nprint(vif_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 feature         VIF\n0              Intercept  110.301908\n1              lake[T.B]   46.505809\n2              lake[T.C]   47.455623\n3            fish_length    3.122694\n4  lake[T.B]:fish_length   47.367520\n5  lake[T.C]:fish_length   49.942831\n```\n\n\n:::\n:::\n\n\n:::\n\nThe posterior predictive check looks alright, and there's no high leverage points to worry about, but we seem to have some potential issues around our main effect of `lake` along with the `lake:fish_length` interaction.\n\nThis is often a sign that that the interaction term is unnecessary. Let's test that theory with some significance testing and model comparison.\n\n### Significance & model comparison\n\nLet's see whether any of our predictors are significant (main effects and/or interaction effect).\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe can use the trusty `anova` and `step` functions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(nb_para, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in anova.negbin(nb_para, test = \"Chisq\"): tests made without\nre-estimating 'theta'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel: Negative Binomial(3.3786), link: log\n\nResponse: parasite_count\n\nTerms added sequentially (first to last)\n\n                 Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \nNULL                                63    118.202              \nlake              2  19.1628        61     99.040 6.900e-05 ***\nfish_length       1  31.6050        60     67.435 1.889e-08 ***\nlake:fish_length  2   0.1471        58     67.288    0.9291    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nstep(nb_para)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStart:  AIC=613.99\nparasite_count ~ lake * fish_length\n\n                   Df Deviance    AIC\n- lake:fish_length  2   67.435 610.14\n<none>                  67.288 613.99\n\nStep:  AIC=610.14\nparasite_count ~ lake + fish_length\n\n              Df Deviance    AIC\n<none>             67.286 610.14\n- lake         2   84.179 623.03\n- fish_length  1   98.819 639.67\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm.nb(formula = parasite_count ~ lake + fish_length, data = parasites, \n    init.theta = 3.370433436, link = log)\n\nCoefficients:\n(Intercept)        lakeB        lakeC  fish_length  \n    1.78006     -0.40015      0.35282      0.08654  \n\nDegrees of Freedom: 63 Total (i.e. Null);  60 Residual\nNull Deviance:\t    117.9 \nResidual Deviance: 67.29 \tAIC: 612.1\n```\n\n\n:::\n:::\n\n\nAlternatively, we could fit an additive model and compare the two directly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_para_add <- glm.nb(parasite_count ~ lake + fish_length, parasites)\n\nanova(nb_para, nb_para_add)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLikelihood ratio tests of Negative Binomial Models\n\nResponse: parasite_count\n               Model    theta Resid. df    2 x log-lik.   Test    df  LR stat.\n1 lake + fish_length 3.370433        60       -602.1381                       \n2 lake * fish_length 3.378592        58       -601.9912 1 vs 2     2 0.1469037\n    Pr(Chi)\n1          \n2 0.9291809\n```\n\n\n:::\n:::\n\n\nThis tells us that the interaction term is not significant.\n\n## Python\n\nLet's start by fitting a new additive model without our interaction.\n\nAgain, we start by specifying our response variable.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nY = parasites['parasite_count']\n```\n:::\n\n\nThis next bit is much simpler than before, without the need to generate the interaction:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Create dummy variables for 'lake' (switch to True/False values)\nlake_dummies = pd.get_dummies(parasites['lake'], drop_first=True)\n\n# Combine the predictors: fish_length, lake dummies\nX = pd.concat([parasites['fish_length'], lake_dummies], axis=1)\n\n# Add a constant/intercept (required), and make sure that we're using floats\nX = sm.add_constant(X).astype(float)\n```\n:::\n\n\nNow, we can fit our model and look at the summary.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Specify the model (Y, X)\nmodel = NegativeBinomial(Y, X)\n\nnb_para_add = model.fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOptimization terminated successfully.\n         Current function value: 4.704204\n         Iterations: 17\n         Function evaluations: 22\n         Gradient evaluations: 22\n```\n\n\n:::\n:::\n\n\nNow, we want to compare the two models (`nb_para` and `nb_para_add`).\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlrstat = -2*(nb_para_add.llf - nb_para.llf)\n\npvalue = chi2.sf(lrstat, nb_para_add.df_resid - nb_para.df_resid)\n\nprint(lrstat, pvalue)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.14690373762027775 0.9291808672960002\n```\n\n\n:::\n:::\n\n\nThis tells us that the interaction term is not significant.\n:::\n\nDropping the interaction will also solve our VIF problem:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_collinearity(nb_para_add)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Check for Multicollinearity\n\nLow Correlation\n\n        Term  VIF       VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n        lake 1.01 [1.00, 1.29e+14]     1.00      0.99     [0.00, 1.00]\n fish_length 1.01 [1.00, 1.29e+14]     1.00      0.99     [0.00, 1.00]\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Drop the response variable\nX = parasites.drop(columns='parasite_count')\n\n# Create design matrix based on model formula\nX = dmatrix(\"lake + fish_length\", data=parasites, return_type='dataframe')\n\n# Calculate VIF for each feature\nvif_data = pd.DataFrame()\nvif_data['feature'] = X.columns\nvif_data['VIF'] = [variance_inflation_factor(X.values, i)\n                   for i in range(X.shape[1])]\n\nprint(vif_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       feature        VIF\n0    Intercept  37.353114\n1    lake[T.B]   1.254778\n2    lake[T.C]   1.261793\n3  fish_length   1.006317\n```\n\n\n:::\n:::\n\n\n:::\n\nExcellent. Seems we have found a well-fitting model for our `parasites` data!\n\n## Exercises\n\n### Bacteria colonies {#sec-exr_bacteria}\n\n::: {.callout-exercise #ex-bacteria}\n#### Bacteria colonies\n{{< level 3 >}}\n\nIn this exercise, we'll use the `bacteria` dataset.\n\nEach row of the dataset represents a petri dish on which bacterial colonies were grown. Each dish was given one of three antibacterial treatments, and then after enough time had passed (between 12 and 24 hours), the number of colonies on the dish were counted. Due to variation in the lab, not all dishes were assessed at the same time.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbacteria <- read_csv(\"data/bacteria.csv\")\n\nhead(bacteria)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  colony_count treatment incubation_time\n         <dbl> <chr>               <dbl>\n1           37 control                13\n2           34 control                22\n3          100 control                23\n4           47 control                15\n5           61 control                14\n6            4 control                12\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nbacteria = pd.read_csv(\"data/bacteria.csv\")\n\nbacteria.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   colony_count treatment  incubation_time\n0            37   control               13\n1            34   control               22\n2           100   control               23\n3            47   control               15\n4            61   control               14\n```\n\n\n:::\n:::\n\n:::\n\nThe dataset contains three variables in total:\n\n-   The response variable `colony_count`\n-   The `treatment` (control/high/low)\n-   The `incubation_time` (hrs)\n\nYou should:\n\n1. Fit an additive (no interaction) negative binomial model\n2. Visualise the model*\n3. Evaluate whether the assumptions are met & the model fits well\n4. Test the significance of the model versus the null**\n\n*R users, this will involve a bit of thinking; consider using the `broom::augment` function to help you.\n\n**Python users, this will involve adapting previous code in a new way.\n\n:::: {.callout-answer collapse=\"true\"}\n\n#### Fit an additive model\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_petri <- glm.nb(colony_count ~ treatment + incubation_time, bacteria)\n\nsummary(nb_petri)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = colony_count ~ treatment + incubation_time, \n    data = bacteria, init.theta = 2.196271257, link = log)\n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)      2.55945    0.39276   6.517 7.19e-11 ***\ntreatmenthigh   -1.16289    0.18516  -6.280 3.38e-10 ***\ntreatmentlow     0.31331    0.18426   1.700 0.089058 .  \nincubation_time  0.07973    0.02232   3.573 0.000353 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(2.1963) family taken to be 1)\n\n    Null deviance: 174.616  on 89  degrees of freedom\nResidual deviance:  99.189  on 86  degrees of freedom\nAIC: 836.62\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  2.196 \n          Std. Err.:  0.342 \n\n 2 x log-likelihood:  -826.621 \n```\n\n\n:::\n:::\n\n\n## Python\n\nIdentify response variable:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nY = bacteria['colony_count']\n```\n:::\n\n\nSet up predictors:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Create dummy variable for categorical treatment predictor\ntreatment_dummies = pd.get_dummies(bacteria['treatment'], drop_first=True)\n\n# Combine predictors\nX = pd.concat([bacteria['incubation_time'], treatment_dummies], axis=1)\n\n# Add a constant/intercept (required), cast to float\nX = sm.add_constant(X).astype(float)\n```\n:::\n\n\nFit model:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel = NegativeBinomial(Y, X)\n\nnb_petri = model.fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOptimization terminated successfully.\n         Current function value: 4.592339\n         Iterations: 16\n         Function evaluations: 18\n         Gradient evaluations: 18\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(nb_petri.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     NegativeBinomial Regression Results                      \n==============================================================================\nDep. Variable:           colony_count   No. Observations:                   90\nModel:               NegativeBinomial   Df Residuals:                       86\nMethod:                           MLE   Df Model:                            3\nDate:                Tue, 22 Jul 2025   Pseudo R-squ.:                 0.06337\nTime:                        17:04:37   Log-Likelihood:                -413.31\nconverged:                       True   LL-Null:                       -441.27\nCovariance Type:            nonrobust   LLR p-value:                 4.364e-12\n===================================================================================\n                      coef    std err          z      P>|z|      [0.025      0.975]\n-----------------------------------------------------------------------------------\nconst               2.5595      0.381      6.714      0.000       1.812       3.307\nincubation_time     0.0797      0.022      3.611      0.000       0.036       0.123\nhigh               -1.1629      0.190     -6.121      0.000      -1.535      -0.791\nlow                 0.3133      0.185      1.691      0.091      -0.050       0.676\nalpha               0.4553      0.071      6.414      0.000       0.316       0.594\n===================================================================================\n```\n\n\n:::\n:::\n\n:::\n\n#### Visualise the model\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nBecause we've fitted a negative binomial model without an interaction term, we can't just use `geom_smooth` (it will automatically include the interaction, which is incorrect).\n\nSo, we're going to use the `broom::augment` function to extract some fitted values. We need to exponentiate these values to get the *actual* predicted counts, which we can then model with `geom_line`, like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\n\n# created augmented model object\npetri_aug <- augment(nb_petri)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `augment()` method for objects of class `negbin` is not maintained by the broom team, and is only supported through the `glm` tidier method. Please be cautious in interpreting and reporting broom output.\n\nThis warning is displayed once per session.\n```\n\n\n:::\n\n```{.r .cell-code}\n# add a new predicted column (exp(fitted))\npetri_aug$.predicted <- exp(petri_aug$.fitted) \n\nggplot(petri_aug, aes(x = incubation_time, y = colony_count, colour = treatment)) +\n  geom_point() +\n  geom_line(mapping = aes(y = .predicted), linewidth = 1)\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\n\nHere's a more efficient way of doing exactly the same thing - we put the augmented object in directly as our data, and do the exponentiation inside the `geom_line` `aes` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(augment(nb_petri), aes(x = incubation_time, y = colony_count, colour = treatment)) +\n  geom_point() +\n  geom_line(mapping = aes(y = exp(.fitted)), linewidth = 1)\n```\n:::\n\n\nNotice how this is subtly different from the model we would've visualised, if we'd just used `geom_smooth`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(petri_aug, aes(x = incubation_time, y = colony_count, colour = treatment)) +\n  geom_point() +\n  geom_smooth(method = \"glm.nb\", se = FALSE) +\n  labs(title = \"This is not the model we wanted!\")\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-47-1.png){width=672}\n:::\n:::\n\n\n\n## Python\n\nWe can copy and adapt the code we used for the `parasites` example in the main body of the chapter - just remember to change all the names!\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Get unique treatment values\ntreatment_levels = bacteria['treatment'].unique()\n\n# Create prediction grid for each lake\nnew_data_nb = pd.concat([\n    pd.DataFrame({\n        'incubation_time': np.linspace(12, 24, 100), # set sensible start & end!\n        'treatment': treatment\n    }) for treatment in treatment_levels\n])\n\n# Repeat the transformations we used when fitting the model\ntreatment_dummies = pd.get_dummies(new_data_nb['treatment'], drop_first=True)\nX_new = pd.concat([new_data_nb['incubation_time'], treatment_dummies], axis=1)\nX_new = sm.add_constant(X_new).astype(float)\n\n# Now we can safely predict:\nnew_data_nb['pred'] = nb_petri.predict(X_new)\n\nnew_data_nb.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   incubation_time treatment       pred\n0        12.000000   control  33.657760\n1        12.121212   control  33.984624\n2        12.242424   control  34.314663\n3        12.363636   control  34.647907\n4        12.484848   control  34.984387\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(bacteria, aes(x = \"incubation_time\",\n                          y = \"colony_count\",\n                          colour = \"treatment\")) +\n   geom_point() +\n   geom_line(new_data_nb, aes(x = \"incubation_time\", y = \"pred\",\n                              colour = \"treatment\"), size = 1))\n                              \np.show()\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-49-1.png){width=614}\n:::\n:::\n\n:::\n\n#### Evaluate assumptions & fit\n\nWe don't need to worry about dispersion - we're explicitly modelling that, rather than making any assumptions.\n\nWe can be reasonably sure we've chosen the right response variable distribution and link function; these are clearly count data.\n\nWith the info we've got, we don't have any reason to be worried about independence. If, however, we found out more about the design - for example, that the petri dishes had been processed in batches, perhaps by different researchers - that might set off alarm bells.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(nb_petri, check = c('pp_check', 'outliers', 'vif'))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCannot simulate residuals for models of class `negbin`. Please try\n  `check_model(..., residual_type = \"normal\")` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-50-3.png){width=672}\n:::\n\n```{.r .cell-code}\ncheck_collinearity(nb_petri)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Check for Multicollinearity\n\nLow Correlation\n\n            Term  VIF   VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n       treatment 1.08 [1.01, 2.25]     1.04      0.92     [0.44, 0.99]\n incubation_time 1.08 [1.01, 2.25]     1.04      0.92     [0.44, 0.99]\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_outliers(nb_petri, threshold = list('cook'=0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.5).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\nNo obvious issues to report!\n\n## Python\n\nRefit the model with `smf.glm`, so we can access `get_influence`. Don't forget to include the estimated `alpha`.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nalpha_est = nb_petri.params['alpha']\n\nmodel = smf.glm(formula='colony_count ~ treatment + incubation_time',\n                data=bacteria,\n                family=sm.families.NegativeBinomial(alpha = alpha_est))\n\nglm_nb_petri = model.fit()\n```\n:::\n\n\nNow we can check influential points:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ninfluence = glm_nb_petri.get_influence()\n\ncooks = influence.cooks_distance[0]\n\ninfluential_points = np.where(cooks > 0.5)[0] # Set appropriate threshold here\n\nprint(\"Influential points:\", influential_points)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluential points: [88]\n```\n\n\n:::\n:::\n\n\nWe have one possible influential point; if this were a real analysis, we would want to follow up on this now, e.g., removing it and refitting, and seeing if our model shifts dramatically.\n\n(Spoiler alert - it doesn't!)\n\nCollinearity/variance inflation factors:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Drop the response variable\nX = bacteria.drop(columns='colony_count')\n\n# Create design matrix based on model formula\nX = dmatrix(\"treatment + incubation_time\", data=bacteria, return_type='dataframe')\n\n# Calculate VIF for each feature\nvif_data = pd.DataFrame()\nvif_data['feature'] = X.columns\nvif_data['VIF'] = [variance_inflation_factor(X.values, i)\n                   for i in range(X.shape[1])]\n\nprint(vif_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             feature        VIF\n0          Intercept  28.462829\n1  treatment[T.high]   1.379350\n2   treatment[T.low]   1.435343\n3    incubation_time   1.079513\n```\n\n\n:::\n:::\n\n\nNo issues with the VIF values!\n:::\n\n#### Compare model to null\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_petri_null <- glm.nb(colony_count ~ 1, bacteria)\n\nanova(nb_petri, nb_petri_null)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLikelihood ratio tests of Negative Binomial Models\n\nResponse: colony_count\n                        Model    theta Resid. df    2 x log-lik.   Test    df\n1                           1 1.220838        89       -882.5434             \n2 treatment + incubation_time 2.196271        86       -826.6210 1 vs 2     3\n  LR stat.      Pr(Chi)\n1                      \n2 55.92243 4.364176e-12\n```\n\n\n:::\n:::\n\n\n## Python\n\nWe've not constructed a null model yet earlier in this chapter, so don't worry if you didn't figure this bit out on your own.\n\nWe still need to set up a `Y` response and an `X` predictor matrix. However, since we only want to regress `colony_count ~ 1`, our `X` matrix just needs to be a column of 1s, with the same length as `Y`.\n\nWe can set that up like this:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nY = bacteria['colony_count']\nX = np.ones((len(Y), 1))\n```\n:::\n\n\nFrom here, the model fitting proceeds exactly as before.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel = NegativeBinomial(Y, X)\n\nnb_petri_null = model.fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOptimization terminated successfully.\n         Current function value: 4.903019\n         Iterations: 6\n         Function evaluations: 7\n         Gradient evaluations: 7\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(nb_petri_null.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     NegativeBinomial Regression Results                      \n==============================================================================\nDep. Variable:           colony_count   No. Observations:                   90\nModel:               NegativeBinomial   Df Residuals:                       89\nMethod:                           MLE   Df Model:                            0\nDate:                Tue, 22 Jul 2025   Pseudo R-squ.:               3.734e-12\nTime:                        17:04:38   Log-Likelihood:                -441.27\nconverged:                       True   LL-Null:                       -441.27\nCovariance Type:            nonrobust   LLR p-value:                       nan\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          3.9035      0.097     40.423      0.000       3.714       4.093\nalpha          0.8191      0.116      7.049      0.000       0.591       1.047\n==============================================================================\n```\n\n\n:::\n:::\n\n\nWe can see that the model, indeed, only contains a constant (intercept) with no predictors. That's what we wanted.\n\nNow, we want to compare the two models (`nb_petri` and `nb_petri_null`). This reuses the likelihood ratio test code we've been using so far in the course:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nlrstat = -2*(nb_petri_null.llf - nb_petri.llf)\n\npvalue = chi2.sf(lrstat, nb_petri_null.df_resid - nb_petri.df_resid)\n\nprint(lrstat, pvalue)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n55.92242554561949 4.364156630706304e-12\n```\n\n\n:::\n:::\n\n:::\n\nIn conclusion: our additive model is significant over the null, and there are no glaring concerns with assumptions that are not met. \n\nOur visualisation of the model seems sensible too. The number of colonies increases with incubation time - this seems very plausible - and the high antibacterial condition definitely is stunted compared to the control, as we might expect.\n\nWhy does the low antibacterial dose condition seem to have more growth than the control? Well, this could just be a fluke. If we repeated the experiment the effect might vanish. \n\nOr, it might be an indication of a stress-induced growth response in those dishes (i.e., a small amount of antibacterial treatment reveals some sort of resistance).\n::::\n:::\n\n### Galapagos models {#sec-exr_galapagos}\n\n::: {.callout-exercise #ex-galapagos}\n\n{{< level 3 >}}\n\nFor this exercise we'll be using the data from `data/galapagos.csv`.\n\nIn this dataset, each row corresponds to one of the 30 Galapagos islands. The relationship between the number of plant species (`species`) and several geographic variables is of interest:\n\n* `endemics` – the number of endemic species\n* `area` – the area of the island km<sup>2</sup>\n* `elevation` – the highest elevation of the island (m)\n* `nearest` – the distance from the nearest island (km)\n\nHowever, fitting both a Poisson and a negative binomial regression produce quite bad results, with strange fit. \n\nIn this exercise, you should:\n\n1. Fit and visualise a Poisson model\n2. Fit and visualise a negative binomial model\n2. Explore ways to improve the fit of the model\n\n(Hint: just because we're fitting a GLM, doesn't mean we can't still transform our data!)\n\n::::: {.callout-warning collapse=\"true\"}\n#### A note for Python users\n\nDue to the small (near-zero) beta coefficients for these data, the `NegativeBinomial` method we've been using struggles to converge on a successful model. Therefore, there is no Python code provided for this example.\n\nHowever, you might find it useful to read through the answer regardless - this is a very interesting dataset!\n:::::\n\n:::: {.callout-answer collapse=\"true\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngalapagos <- read_csv(\"data/galapagos.csv\")\n```\n:::\n\n\n#### Fitting a Poisson model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_gal <- glm(species ~ area + endemics + elevation + nearest,\n               data = galapagos, family = \"poisson\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(galapagos, aes(endemics, species)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", se = FALSE, fullrange = TRUE, \n              method.args = list(family = \"poisson\")) +\n  labs(title = \"Poisson\")\n\np1\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-60-1.png){width=672}\n:::\n:::\n\n\nOur model is doing okay over on the right hand side, but it's not really doing a good job in the bottom left corner - which is where most of the data points are clustered!\n\n#### Fitting a negative binomial model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_gal <- glm.nb(species ~ area + endemics + elevation + nearest,\n               data = galapagos)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np2 <- ggplot(galapagos, aes(endemics, species)) +\n  geom_point() +\n  geom_smooth(method = \"glm.nb\", se = FALSE, fullrange = TRUE) +\n  labs(title = \"Negative binomial\")\n\np2\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-62-1.png){width=672}\n:::\n:::\n\n\nThis model does a better job in the lower left, but now is getting things a bit wrong over on the far right.\n\n#### Improving the fit\n\nIs there anything we can do to improve on these two models?\n\nThere appears to be a power relationship between `species` and `endemics`. So, one thing we could do is log-transform the response (`species`) and predictor (`endemics`) variables.\n\nIf we log-transform them both and put them on a scatterplot, they look like this - linear?!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = galapagos,\n       aes(x = log(endemics),\n           y = log(species))) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-63-1.png){width=672}\n:::\n:::\n\n\nWe could add a regression line to this. \n\nOr, we could just log-transform `endemics` and fit a negative binomial model to that, without also log-transforming `species`. Let's do all of this and plot them together with the original Poisson and Negative binomial models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np3 <- ggplot(galapagos, aes(log(endemics), log(species))) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, fullrange = TRUE,\n              method.args = list(family = poisson)) +\n  labs(title = \"Linear model of log-log\")\n\np4 <- ggplot(galapagos, aes(log(endemics), species)) +\n  geom_point() +\n  geom_smooth(method = \"glm.nb\", se = FALSE, fullrange = TRUE) +\n  ylim(0, 500) +\n  labs(title = \"Negative binomial of log(endemics)\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\n\np1 + p2 + p3 + p4 +\n  plot_annotation(tag_levels = \"A\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: In lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok, \n    ...) :\n extra argument 'family' will be disregarded\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](glm-practical-negative-binomial_files/figure-html/unnamed-chunk-65-1.png){width=672}\n:::\n:::\n\n\nFrom this it is clear that the negative binomial model fitted to `species ~ log(endemics)` in panel D produces a much better fit than the original fit in panel B.\n\nEqually, looking at the relationship between `log(species) ~ log(endemics)` in panel C it illustrates that this is pretty well-modelled using a linear line.\n\nThere is a slight issue, though. \n\nIf you look carefully then you see that in both panels C and D there is a stray value left of zero, almost escaping past the y-axis. There is also a warning message, saying `Removed 1 row containing non-finite outside the scale range`. \n\nWith a closer look at the dataset, we can see that there is one island where the number of `endemics` is equal to 0: \n\n\n::: {.cell}\n\n```{.r .cell-code}\ngalapagos |> \n  arrange(endemics) |>\n  head(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  species endemics  area elevation nearest\n    <dbl>    <dbl> <dbl>     <dbl>   <dbl>\n1      24        0  0.08        93       6\n```\n\n\n:::\n:::\n\n\nIf we take `log(0)` we get minus infinity, which isn't biologically possible. This is where the problem lies.\n\nWe could adjust for this by adding a \"pseudo-count\", or adding `1` to all of the counts. If that is acceptable or not is a matter of debate and we'll leave it to you to ponder over this. \n\nWhatever you do, the most important thing is to make sure that you are transparent and clear on what you are doing and what the justification for it it.\n::::\n:::\n\n## Summary\n\n::: {.callout-tip}\n#### Key points\n\n- Negative binomial regression relaxes the assumption made by Poisson regressions that the variance is equal to the mean (dispersion = 1)\n- In a negative binomial regression the dispersion parameter $\\theta$ is estimated from the data\n- However, they both use the log link function and often produce similar-looking models\n:::\n",
    "supporting": [
      "glm-practical-negative-binomial_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}