---
title: "Proportional response"
---

```{r}
#| echo: false
#| message: false
# adjust and load as needed
source(file = "setup_files/setup.R")
```

```{python}
#| echo: false
#| message: false
import shutup;shutup.please()
exec(open('setup_files/setup.py').read())
```

::: {.callout-tip}
## Learning outcomes

-   How do I analyse proportion responses?
-   Be able to create a logistic model to test proportion response variables
-   Be able to plot the data and fitted curve
-   Assess the significance of the fit
:::

## Libraries and functions

::: {.callout-note collapse="true"}
## Click to expand

::: {.panel-tabset group="language"}
## R

### Libraries
### Functions

## Python

### Libraries

```{python}
#| eval: false
# A maths library
import math
# A Python data analysis and manipulation tool
import pandas as pd

# Python equivalent of `ggplot2`
from plotnine import *

# Statistical models, conducting tests and statistical data exploration
import statsmodels.api as sm

# Convenience interface for specifying models using formula strings and DataFrames
import statsmodels.formula.api as smf

# Needed for additional probability functionality
from scipy.stats import *
```

### Functions
:::
:::

The example in this section uses the following data set:

`data/challenger.csv`

These data, obtained from the [faraway package](https://www.rdocumentation.org/packages/faraway/versions/1.0.7) in R, contain information related to the explosion of the USA Space Shuttle Challenger on 28 January, 1986. An investigation after the disaster traced back to certain joints on one of the two solid booster rockets, each containing O-rings that ensured no exhaust gases could escape from the booster.

The night before the launch was unusually cold, with temperatures below freezing. The final report suggested that the cold snap during the night made the o-rings stiff, and unable to adjust to changes in pressure. As a result, exhaust gases leaked away from the solid booster rockets, causing one of them to break loose and rupture the main fuel tank, leading to the final explosion.

The question we're trying to answer in this session is: based on the data from the previous flights, would it have been possible to predict the failure of most o-rings on the Challenger flight?

## Load and visualise the data

First we load the data, then we visualise it.

::: {.panel-tabset group="language"}
## R

```{r}
challenger <- read_csv("data/challenger.csv")
```

## Python

```{python}
challenger_py = pd.read_csv("data/challenger.csv")
```

:::

The data set contains several columns:

1.  `temp`, the launch temperature in degrees Fahrenheit
2.  `damage`, the number of o-rings that showed erosion

Before we have a further look at the data, let's calculate the proportion of damaged o-rings (`prop_damaged`) and the total number of o-rings (`total`) and update our data set.

::: {.panel-tabset group="language"}
## R

```{r}
challenger <-
challenger %>%
  mutate(total = 6,                     # total number of o-rings
         intact = 6 - damage,           # number of undamaged o-rings
         prop_damaged = damage / total) # proportion damaged o-rings

challenger
```

## Python

```{python}
challenger_py['total'] = 6
challenger_py['intact'] = challenger_py['total'] - challenger_py['damage']
challenger_py['prop_damaged'] = challenger_py['damage'] / challenger_py['total']
```

:::

Plotting the proportion of damaged o-rings against the launch temperature shows the following picture:

::: {.panel-tabset group="language"}
## R

```{r}
ggplot(challenger, aes(x = temp, y = prop_damaged)) +
  geom_point()
```

## Python

```{python}
#| results: hide
(ggplot(challenger_py,
         aes(x = "temp",
             y = "prop_damaged")) +
     geom_point())
```

:::

The point on the left is the data point corresponding to the coldest flight experienced before the disaster, where five damaged o-rings were found. Fortunately, this did not result in a disaster.

Here we'll explore if we could have reasonably predicted the failure of both o-rings on the Challenger flight, where the launch temperature was 31 degrees Fahrenheit.

## Creating a suitable model

We only have 23 data points in total. So we're building a model on not that much data - we should keep this in mind when we draw our conclusions!

We are using a logistic regression for a proportion response in this case, since we're interested in the proportion of o-rings that are damaged.

We can define this as follows:

::: {.panel-tabset group="language"}
## R

```{r}
glm_chl <- glm(cbind(damage, intact) ~ temp,
               family = binomial,
               data = challenger)
```

Defining the relationship for proportion responses is a bit annoying, where you have to give the `glm` model a two-column matrix to specify the response variable.

Here, the first column corresponds to the number of damaged o-rings, whereas the second column refers to the number of intact o-rings. We use the `cbind()` function to bind these two together into a matrix.

## Python

```{python}
# create a generalised linear model
model = smf.glm(formula = "damage + intact ~ temp",
                family = sm.families.Binomial(),
                data = challenger_py)
# and get the fitted parameters of the model
glm_chl_py = model.fit()
```

:::

## Model output

That's the easy part done! The trickier part is interpreting the output. First of all, we'll get some summary information.

::: {.panel-tabset group="language"}
## R

Next, we can have a closer look at the results:

```{r}
summary(glm_chl)
```

We can see that the p-values of the `intercept` and `temp` are significant. We can also use the intercept and `temp` coefficients to construct the logistic equation, which we can use to sketch the logistic curve.

## Python

```{python}
print(glm_chl_py.summary())
```
:::

$$E(prop \ failed\ orings) = \frac{\exp{(11.66 -  0.22 \times temp)}}{1 + \exp{(11.66 -  0.22 \times temp)}}$$

Let's see how well our model would have performed if we would have fed it the data from the ill-fated Challenger launch.

::: {.panel-tabset group="language"}
## R

```{r}
#| message: false
ggplot(challenger, aes(temp, prop_damaged)) +
  geom_point() +
  geom_smooth(method = "glm", se = FALSE, fullrange = TRUE, 
              method.args = list(family = binomial)) +
  xlim(25,85)
```

## Python

We can get the predicted values for the model as follows:

```{python}
challenger_py['predicted_values'] = glm_chl_py.predict()

challenger_py.head()
```

This would only give us the predicted values for the data we already have. Instead we want to extrapolate to what would have been predicted for a wider range of temperatures. Here, we use a range of $[25, 85]$ degrees Fahrenheit.

```{python}
model = pd.DataFrame({'temp': list(range(25, 86))})

model["pred"] = glm_chl_py.predict(model)

model.head()
```

```{python}
#| results: hide
(ggplot(challenger_py,
         aes(x = "temp",
             y = "prop_damaged")) +
     geom_point() +
     geom_line(model, aes(x = "temp", y = "pred"), colour = "blue", size = 1))
```


::: {.callout-note collapse=true}
## Generating predicted values

::: {.panel-tabset group="language"}
## R

Another way of doing this it to generate a table with data for a range of temperatures, from 25 to 85 degrees Fahrenheit, in steps of 1. We can then use these data to generate the logistic curve, based on the fitted model.

```{r}
# create a table with sequential numbers ranging from 25 to 85
model <- tibble(temp = seq(25, 85, by = 1)) %>% 
  # add a new column containing the predicted values
  mutate(.pred = predict(glm_chl, newdata = ., type = "response"))

ggplot(model, aes(temp, .pred)) +
  geom_line()
```

```{r}
# plot the curve and the original data
ggplot(model, aes(temp, .pred)) +
  geom_line(colour = "blue") +
  geom_point(data = challenger, aes(temp, prop_damaged)) +
  # add a vertical line at the disaster launch temperature
  geom_vline(xintercept = 31, linetype = "dashed")
```

It seems that there was a high probability of both o-rings failing at that launch temperature. One thing that the graph shows is that there is a lot of uncertainty involved in this model. We can tell, because the fit of the line is very poor at the lower temperature range. There is just very little data to work on, with the data point at 53 F having a large influence on the fit.

## Python

We already did this above, since this is the most straightforward way of plotting the model in Python.

:::
:::
:::

## Exercises

### Predicting failure {#sec-exr_failure}

:::{.callout-exercise}

{{< level 2 >}}

The data point at 53 degrees Fahrenheit is quite influential for the analysis. Remove this data point and repeat the analysis. Is there still a predicted link between launch temperature and o-ring failure?

::: {.callout-answer collapse="true"}

::: {.panel-tabset group="language"}
## R

First, we need to remove the influential data point:

```{r}
challenger_new <- challenger %>% filter(temp != 53)
```

We can create a new generalised linear model, based on these data:

```{r}
glm_chl_new <- glm(cbind(damage, intact) ~ temp,
               family = binomial,
               data = challenger_new)
```

We can get the model parameters as follows:

```{r}
summary(glm_chl_new)
```

```{r}
#| message: false
ggplot(challenger_new, aes(temp, prop_damaged)) +
  geom_point() +
  geom_smooth(method = "glm", se = FALSE, fullrange = TRUE, 
              method.args = list(family = binomial)) +
  xlim(25,85) +
  # add a vertical line at 53 F temperature
  geom_vline(xintercept = 53, linetype = "dashed")
```

The prediction proportion of damaged o-rings is markedly less than what was observed.

Before we can make any firm conclusions, though, we need to check our model:

```{r}
1- pchisq(12.633,20)
```

We get quite a high score (around 0.9) for this, which tells us that our goodness of fit is pretty rubbish â€“ our points are not very close to our curve, overall.

Is the model any better than the null though?

```{r}
1 - pchisq(16.375 - 12.633, 21 - 20)

anova(glm_chl_new, test = 'Chisq')
```

However, the model is not significantly better than the null in this case, with a p-value here of just over 0.05 for both of these tests (they give a similar result since, yet again, we have just the one predictor variable).

## Python

First, we need to remove the influential data point:


```{python}
challenger_new_py = challenger_py.query("temp != 53")
```

We can create a new generalised linear model, based on these data:

```{python}
# create a generalised linear model
model = smf.glm(formula = "damage + intact ~ temp",
                family = sm.families.Binomial(),
                data = challenger_new_py)
# and get the fitted parameters of the model
glm_chl_new_py = model.fit()
```

We can get the model parameters as follows:

```{python}
print(glm_chl_new_py.summary())
```

Generate new model data:

```{python}
model = pd.DataFrame({'temp': list(range(25, 86))})

model["pred"] = glm_chl_new_py.predict(model)

model.head()
```

```{python}
#| results: hide
#| message: false
(ggplot(challenger_new_py,
         aes(x = "temp",
             y = "prop_damaged")) +
     geom_point() +
     geom_line(model, aes(x = "temp", y = "pred"), colour = "blue", size = 1) +
     # add a vertical line at 53 F temperature
     geom_vline(xintercept = 53, linetype = "dashed"))
```

The prediction proportion of damaged o-rings is markedly less than what was observed.

Before we can make any firm conclusions, though, we need to check our model:

```{python}
chi2.sf(12.633, 20)
```

We get quite a high score (around 0.9) for this, which tells us that our goodness of fit is pretty rubbish â€“ our points are not very close to our curve, overall.

Is the model any better than the null though?

First we need to define the null model:

```{python}
# create a linear model
model = smf.glm(formula = "damage + intact ~ 1",
                family = sm.families.Binomial(),
                data = challenger_new_py)
# and get the fitted parameters of the model
glm_chl_new_null_py = model.fit()

print(glm_chl_new_null_py.summary())
```

```{python}
chi2.sf(16.375 - 12.633, 21 - 20)
```

However, the model is not significantly better than the null in this case, with a p-value here of just over 0.05 for both of these tests (they give a similar result since, yet again, we have just the one predictor variable).
:::

So, could NASA have predicted what happened? This model is not significantly different from the null, i.e., temperature is not a significant predictor. Note that itâ€™s only marginally non-significant, and we do have a high goodness-of-fit value.

It is possible that if more data points were available that followed a similar trend, the story might be different). Even if we did use our non-significant model to make a prediction, it doesnâ€™t give us a value anywhere near 5 failures for a temperature of 53 degrees Fahrenheit. So overall, based on the model weâ€™ve fitted with these data, there was no indication that a temperature just a few degrees cooler than previous missions could have been so disastrous for the Challenger.
:::
:::

## Summary

::: {.callout-tip}
#### Key points

-   We can use a logistic model for proportion response variables

:::
