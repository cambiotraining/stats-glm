---
title: "Proportional response"
lightbox: true
---

```{r}
#| echo: false
#| message: false
# adjust and load as needed
source(file = "setup_files/setup.R")
```

```{python}
#| echo: false
#| message: false
import shutup;shutup.please()
exec(open('setup_files/setup.py').read())
```

::: {.callout-tip}
## Learning outcomes

-   Be able to analyse proportional response variables
-   Be able to create a logistic model to test proportional response variables
-   Be able to plot the data and fitted curve
:::

## Libraries and functions

::: {.callout-note collapse="true"}
## Click to expand

::: {.panel-tabset group="language"}
## R

### Libraries

```{r}
#| eval: false
library(broom)
library(tidyverse)
library(ggResidpanel)
```

### Functions

```{r}
#| eval: false
# create diagnostic plots
ggResidpanel::resid_panel()
```

## Python

### Libraries

```{python}
#| eval: false
import math
import pandas as pd
from plotnine import *
import statsmodels.api as sm
import statsmodels.formula.api as smf
from scipy.stats import *
```
:::
:::

## The Challenger dataset

The example in this section uses the following data set:

`data/challenger.csv`

These data, obtained from the [faraway package](https://www.rdocumentation.org/packages/faraway/versions/1.0.7) in R, contain information related to the explosion of the USA Space Shuttle Challenger on 28 January, 1986. An investigation after the disaster traced back to certain joints on one of the two solid booster rockets, each containing O-rings that ensured no exhaust gases could escape from the booster.

The night before the launch was unusually cold, with temperatures below freezing. The final report suggested that the cold snap during the night made the o-rings stiff, and unable to adjust to changes in pressure. As a result, exhaust gases leaked away from the solid booster rockets, causing one of them to break loose and rupture the main fuel tank, leading to the final explosion.

The question we're trying to answer in this session is: based on the data from the previous flights, would it have been possible to predict the failure of most o-rings on the Challenger flight?

## Load and visualise the data

First we load the data, then we visualise it.

::: {.panel-tabset group="language"}
## R

```{r}
challenger <- read_csv("data/challenger.csv")
```

## Python

```{python}
challenger_py = pd.read_csv("data/challenger.csv")
```
:::

The data set contains several columns:

1.  `temp`, the launch temperature in degrees Fahrenheit
2.  `damage`, the number of o-rings that showed erosion

Before we have a further look at the data, let's calculate the proportion of damaged o-rings (`prop_damaged`) and the total number of o-rings (`total`) and update our data set.

::: {.panel-tabset group="language"}
## R

```{r}
challenger <-
challenger %>%
  mutate(total = 6,                     # total number of o-rings
         intact = 6 - damage,           # number of undamaged o-rings
         prop_damaged = damage / total) # proportion damaged o-rings

challenger
```

## Python

```{python}
challenger_py['total'] = 6
challenger_py['intact'] = challenger_py['total'] - challenger_py['damage']
challenger_py['prop_damaged'] = challenger_py['damage'] / challenger_py['total']
```

:::

Plotting the proportion of damaged o-rings against the launch temperature shows the following picture:

::: {.panel-tabset group="language"}
## R

```{r}
ggplot(challenger, aes(x = temp, y = prop_damaged)) +
  geom_point()
```

## Python

```{python}
#| results: hide
p = (ggplot(challenger_py,
         aes(x = "temp",
             y = "prop_damaged")) +
     geom_point())
     
p.show()
```

:::

The point on the left is the data point corresponding to the coldest flight experienced before the disaster, where five damaged o-rings were found. Fortunately, this did not result in a disaster.

Here we'll explore if we could have reasonably predicted the failure of both o-rings on the Challenger flight, where the launch temperature was 31 degrees Fahrenheit.

## Creating a suitable model

We only have 23 data points in total. So we're building a model on not that much data - we should keep this in mind when we draw our conclusions!

We are using a logistic regression for a proportion response in this case, since we're interested in the proportion of o-rings that are damaged.

We can define this as follows:

::: {.panel-tabset group="language"}
## R

```{r}
glm_chl <- glm(cbind(damage, intact) ~ temp,
               family = binomial,
               data = challenger)
```

Defining the relationship for proportion responses is a bit annoying, where you have to give the `glm` model a two-column matrix to specify the response variable.

Here, the first column corresponds to the number of damaged o-rings, whereas the second column refers to the number of intact o-rings. We use the `cbind()` function to bind these two together into a matrix.

## Python

```{python}
# create a generalised linear model
model = smf.glm(formula = "damage + intact ~ temp",
                family = sm.families.Binomial(),
                data = challenger_py)
# and get the fitted parameters of the model
glm_chl_py = model.fit()
```

:::

If we're using the original observations, we need to supply both the number of damaged o-rings *and* the number of intact ones.

::: {.callout-warning}
### Why don't we use `prop_damaged` as our response variable?

You might have noticed that when we write our model formula, we are specifically writing `cbind(damage, intact)` (R) or `damage + intact` (Python), instead of the `prop_damaged` variable we used for plotting.

This is very deliberate - it's **absolutely essential** we do this, in order to fit the correct model.

When modelling our data, we need to provide the function with both the number of successes (damaged o-rings) and the number of failures (intact o-rings) - and therefore, implicitly, the total number of o-rings - in order to properly model our proportional variable.

If we provide it with just the `prop_damaged`, then R/Python will incorrectly think our response variable is **fractional**.

A fractional variable is not constructed from a series of trials with successes/failures. It doesn't have trials - there's just a single value somewhere between 0 and 1 (or a percentage). An example of a fractional response variable might be what percentage of rocket fuel was used on a launch. We would not model this response variable with a logistic regression.

![Fractional vs proportional variables](images/fractional-vs-proportional.png){width=40%}
:::

## Model output

That's the easy part done! The trickier part is interpreting the output. First of all, we'll get some summary information.

::: {.panel-tabset group="language"}
## R

Next, we can have a closer look at the results:

```{r}
summary(glm_chl)
```

We can see that the p-values of the `intercept` and `temp` are significant. We can also use the intercept and `temp` coefficients to construct the logistic equation, which we can use to sketch the logistic curve.

## Python

```{python}
print(glm_chl_py.summary())
```
:::

$$E(prop \ failed\ orings) = \frac{\exp{(11.66 -  0.22 \times temp)}}{1 + \exp{(11.66 -  0.22 \times temp)}}$$

Let's see how well our model would have performed if we would have fed it the data from the ill-fated Challenger launch.

::: {.panel-tabset group="language"}
## R

```{r}
#| message: false
ggplot(challenger, aes(temp, prop_damaged)) +
  geom_point() +
  geom_smooth(method = "glm", se = FALSE, fullrange = TRUE, 
              method.args = list(family = binomial)) +
  xlim(25,85)
```

## Python

We can get the predicted values for the model as follows:

```{python}
challenger_py['predicted_values'] = glm_chl_py.predict()

challenger_py.head()
```

This would only give us the predicted values for the data we already have. Instead we want to extrapolate to what would have been predicted for a wider range of temperatures. Here, we use a range of $[25, 85]$ degrees Fahrenheit.

```{python}
model = pd.DataFrame({'temp': list(range(25, 86))})

model["pred"] = glm_chl_py.predict(model)

model.head()
```

```{python}
#| results: hide
p = (ggplot(challenger_py,
         aes(x = "temp",
             y = "prop_damaged")) +
     geom_point() +
     geom_line(model, aes(x = "temp", y = "pred"), colour = "blue", size = 1))
     
p.show()
```


::: {.callout-note collapse=true}
## Generating predicted values

::: {.panel-tabset group="language"}
## R

Another way of doing this it to generate a table with data for a range of temperatures, from 25 to 85 degrees Fahrenheit, in steps of 1. We can then use these data to generate the logistic curve, based on the fitted model.

```{r}
# create a table with sequential numbers ranging from 25 to 85
model <- tibble(temp = seq(25, 85, by = 1)) %>% 
  # add a new column containing the predicted values
  mutate(.pred = predict(glm_chl, newdata = ., type = "response"))

ggplot(model, aes(temp, .pred)) +
  geom_line()
```

```{r}
# plot the curve and the original data
ggplot(model, aes(temp, .pred)) +
  geom_line(colour = "blue") +
  geom_point(data = challenger, aes(temp, prop_damaged)) +
  # add a vertical line at the disaster launch temperature
  geom_vline(xintercept = 31, linetype = "dashed")
```

It seems that there was a high probability of both o-rings failing at that launch temperature. One thing that the graph shows is that there is a lot of uncertainty involved in this model. We can tell, because the fit of the line is very poor at the lower temperature range. There is just very little data to work on, with the data point at 53 F having a large influence on the fit.

## Python

We already did this above, since this is the most straightforward way of plotting the model in Python.

:::
:::
:::

## Exercises

### Rats and levers {#sec-exr_levers}

::: {.callout-exercise #ex-levers}
{{< level 2 >}}

This exercises uses the dataset `levers.csv`.

These data are from a simple animal behavioural experiment. Prior to testing, rats were trained to press levers for food rewards. On each trial, there were two levers, and the "correct" lever is determined by an audio cue.

The rats could vary in three different ways, which may impact their task performance at testing:

-   The `sex` of the rat
-   The `age` of the rat (in weeks)
-   Whether the rat experienced `stress` during the training phase (being exposed to the smell of a predator)

The researcher thinks that the effect of stress may differ between male and female rats.

In this exercise:

1. Visualise these data
2. Fit a model that captures the researcher's hypotheses

:::: {.callout-answer collapse="true"}
#### Load and visualise

::: {.panel-tabset group="language"}
## R

```{r}
#| message: false
#| warning: false
levers <- read_csv("data/levers.csv")

head(levers)
```

## Python

```{python}
levers = pd.read_csv("data/levers.csv")

levers.head()
```
:::

We can see that this dataset contains quite a few columns. Key ones to pay attention to:

-   `trials`; the total number of trials per rat - we're going to need this when fitting our model
-   `correct_presses`; the number of successes (out of the total number of trials) - again, we'll need this for model fitting
-   `prop_correct`; this is $successes/total$, which we'll use for plotting but not model fitting

::: {.panel-tabset group="language"}
## R

```{r}
ggplot(levers, aes(x = rat_age, 
                   y = prop_correct,
                   colour = sex)) +
  facet_wrap(~ stress_type) +
  geom_point()
```

## Python

```{python}
(
  ggplot(levers, aes(x='rat_age', y='prop_correct', colour='sex')) +
  geom_point() +
  facet_wrap('~stress_type')
)
```
:::

There's some visual evidence of an interaction here. In the `control` group, it seems like older rats perform a little better on the task, but there's not much effect of `sex`.

Meanwhile, in the `stressed` group, the female rats seem to be performing better than the male ones.

#### Fit a model

Let's assess those relationships by fitting a logistic model.

::: {.panel-tabset group="language"}
## R

```{r}
# Create a new variable for the number of incorrect presses
levers <- levers %>%
  mutate(incorrect_presses = trials - correct_presses)

# Fit the model
glm_lev <- glm(cbind(correct_presses, incorrect_presses) ~ stress_type * sex + rat_age,
               family = binomial,
               data = levers)
```

## Python

```{python}
# Create a new variable for the number of incorrect presses
levers['incorrect_presses'] = levers['trials'] - levers['correct_presses']

model = smf.glm(formula = "correct_presses + incorrect_presses ~ stress_type * sex + rat_age",
                family = sm.families.Binomial(),
                data = levers)

glm_lev = model.fit()
```
:::

#### Make model predictions

Using this model, let's make a prediction of the expected proportion of correct lever presses for:

- a male rat
- 8 weeks old
- in the stressed condition

First, we look at a summary of the model to extract the beta coefficients we need.

::: {.panel-tabset group="language"}
## R

```{r}
summary(glm_lev)
```

## Python

```{python}
glm_lev.summary()
```
:::

::: {.panel-tabset group="language"}
## R

```{r}
lin_pred <- -2.519 + 
            0.937 * 1 +     # 1 for stressed
            0.506 * 1 +     # 1 for male
            -1.438 * 1 +    # 1 for stressed:male
            0.135 * 8       # 8 weeks old

# these will give identical results
exp(lin_pred) / (1 + exp(lin_pred))
1 / (1 + exp(-lin_pred))
```

## Python

```{python}
lin_pred = (-2.519 + 
           0.937 * 1 +     # 1 for stressed
           0.506 * 1 +     # 1 for male
           -1.438 * 1 +    # 1 for stressed:male
           0.135 * 8)       # 8 weeks old

# these will give identical results
math.exp(lin_pred) / (1 + math.exp(lin_pred))
1 / (1 + math.exp(-lin_pred))
```
:::

This means we would expect an 8 week old stressed male rat to make approximately 19% correct button presses, on average.
::::

:::: {.callout-tip collapse="true"}
### Visualising glm_lev

This is not part of the exercise - it involves quite a bit of new code - but it's something you might want to do with your own data, so we'll show it here.

With multiple predictors, you will have multiple logistic curves. What do they look like, and how can you produce them?

::: {.panel-tabset group="language"}
## R

The first thing we do is create a grid covering all the levels of our categorical predictor, and the full range of available values we have for the continuous predictor. 

```{r}
# Create prediction grid
new_data <- expand.grid(stress_type = levels(factor(levers$stress_type)),
                        sex = levels(factor(levers$sex)),
                        rat_age = seq(min(levers$rat_age), max(levers$rat_age), length.out = 100))

head(new_data)
```

Then, we use the `predict` function to figure out the expected proportion of correct responses at each combination of predictors that exists in that grid.

```{r}
# Predict proportion of correct responses
new_data$predicted_prob <- predict(glm_lev, newdata = new_data, type = "response")
```

We can now use this grid of predictions to produce some nice lines, on top of the actual data points.

```{r}
ggplot(levers, aes(x = rat_age, y = prop_correct,
                     color = stress_type, linetype = sex)) +
  geom_point() +
  geom_line(data = new_data, aes(y = predicted_prob), linewidth = 1)
```

You could facet this plot further if you wanted to, but all the lines together help make the picture quite clear - we can see the interaction between `stress:sex` quite clearly!

## Python

The code to achieve this in Python very quickly becomes long, ugly and unwieldy.

If you're absolutely determined to produce plots like this, you might want to use an IDE that lets you use both R and Python, and switch briefly into R for this!
:::
::::
:::


### Stem cells {#sec-exr_stemcells}

::: {.callout-exercise #ex-stemcells}
{{< level 3 >}}

For this exercise, you will need the dataset `stemcells.csv`.

There's no worked answer for this dataset - we recommend that you compare and discuss your answer with a neighbour.

In this dataset, each row represents a unique culture or population of stem cells (a plate). Each plate is exposed to one of three different `growth_factor_conc` concentration levels (low, medium or high). 

The researcher wanted to record how much of a particular bio-marker was being expressed in the plate, to quantify cell differentiation.

She measured this outcome in multiple ways:

-   `marker_positive_cells`, the number of cells expressing the marker
-   `prop_positive_cells`, the proportion of the `total_cells` count that have the marker
-   `mean_marker_intensity`, the normalised average fluorescence intensity across the plate, measured on a scale between 0 and 1

Between plates, there was also variation in the `time` (days) before observation. This variable should be included as a control/covariate of no interest.

You should:

1. Produce a scatterplot of the data
2. Decide which outcome measurement is appropriate for a logistic regression
3. Fit an appropriate logistic model (with two predictor variables)

::: {.panel-tabset group="language"}
## R

```{r}
#| message: false
#| warning: false
stemcells <- read_csv("data/stemcells.csv")
```

## Python

```{python}
stemcells = pd.read_csv("data/stemcells.csv")
```
:::

:::: {.callout-tip collapse="true"}
#### Hint #1

Remember, you'll need to input & combine two values to make up your response variable.

We won't give away what those variables are (that defeats the point a bit!) but the appropriate code for fitting your logistic regression should look something like this:

::: {.panel-tabset group="language"}
## R

```{r}
#| eval: false
glm_cells <- glm(cbind(var, var) ~ growth_factor_conc + time, 
                 family = binomial,
                 data = stemcells)
```

## Python

```{python}
#| eval: false
model = smf.glm(formula = "var + var ~ growth_factor_conc + time",
                family = sm.families.Binomial(),
                data = stemcells)

glm_cells = model.fit()
```
:::
::::

:::: {.callout-tip collapse="true"}
#### Hint #2

If you're struggling to figure out which of the outcome measures capture which information, here's a little visualisation:

![Measuring markers of differentiation in stem cells](images/stem-cells.png){width=50%}
::::
:::

## Summary

::: {.callout-tip}
#### Key points

-   We can use a logistic model for proportional response variables, just as we did with binary variables
-   Proportional response variables are made up of a number of trials (success/failure), and should not be confused with fractions/percentages
-   Using the equation of a logistic model, we can predict the expected proportion of "successful" trials
:::
